{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For selected ClearCut AOI prepare Planet and Sentinel2 images. Show clearcuts on AOI. Compare quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import rasterio.mask\n",
    "import tempfile\n",
    "import shapely\n",
    "import re\n",
    "\n",
    "from rasterio.features import rasterize, shapes\n",
    "from rasterio.merge import merge\n",
    "from shapely.geometry import Polygon, shape, box\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sentinel2download.downloader import Sentinel2Downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = f\"/home/{os.getenv('NB_USER')}/work\"\n",
    "\n",
    "WORKDIR = os.path.join(BASE, \"notebooks/planet/planet_vs_sentinel\")\n",
    "IMGDIR = os.path.join(WORKDIR, \"planet_imagery\")\n",
    "RESULTS_DIR = os.path.join(BASE, \"results/planet/planet_vs_sentinel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_aoi(path, crs=\"epsg:4326\"):\n",
    "    df = gpd.read_file(path) \n",
    "    if str(df.crs) != crs:\n",
    "        print(f\"{path}: {df.crs}. Transform to {crs}\")\n",
    "    df.to_crs(crs, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_path = os.getenv(\"AOI\", os.path.join(WORKDIR, \"aoi/Horodnie_20191001_20191101.geojson\")) \n",
    "# Pervukhynka_20190801_20190831.geojson \n",
    "# Horodnie_20191001_20191101.geojson\n",
    "# Harkavets_20190501_20190518.geojson\n",
    "\n",
    "aoi = read_aoi(aoi_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2019-10-01'\n",
    "end_date = '2019-11-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_planet(grid, start_date, end_date):\n",
    "    # grid.acquired = pd.to_datetime(grid.acquired)\n",
    "    grid = grid.loc[(grid.ground_control == \"1\") & \n",
    "                    (grid.item_type == \"PSScene4Band\") &\n",
    "                    (grid.quality_category == \"standard\") &\n",
    "                    (grid.cloud_cover == 0) &\n",
    "                    (grid.acquired >= start_date) &\n",
    "                    (grid.acquired <= end_date) &\n",
    "                    (grid.snow_ice_percent == 0) &\n",
    "                    (grid.clear_percent >= 95)].reset_index(drop=True)\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsg_code(longitude, latitude):\n",
    "    \"\"\"\n",
    "    Generates EPSG code from lon, lat\n",
    "    :param longitude: float\n",
    "    :param latitude: float\n",
    "    :return: int, EPSG code\n",
    "    \"\"\"\n",
    "\n",
    "    def _zone_number(lat, lon):\n",
    "        if 56 <= lat < 64 and 3 <= lon < 12:\n",
    "            return 32\n",
    "        if 72 <= lat <= 84 and lon >= 0:\n",
    "            if lon < 9:\n",
    "                return 31\n",
    "            elif lon < 21:\n",
    "                return 33\n",
    "            elif lon < 33:\n",
    "                return 35\n",
    "            elif lon < 42:\n",
    "                return 37\n",
    "\n",
    "        return int((lon + 180) / 6) + 1\n",
    "\n",
    "    zone = _zone_number(latitude, longitude)\n",
    "\n",
    "    if latitude > 0:\n",
    "        return 32600 + zone\n",
    "    else:\n",
    "        return 32700 + zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _intersect(aoi, grid, limit=1):\n",
    "    \"\"\"\n",
    "    Find all tiles that intersects given region with area >= limit km2\n",
    "    :param limit: float, min intersection area in km2\n",
    "    :return: (GeoDataFrame, epsg), precised intersected tiles and UTM zone code\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # Get the indices of the tiles that are likely to be inside the bounding box of the given Polygon\n",
    "    geometry = aoi.geometry[0]\n",
    "\n",
    "    tiles_indexes = list(grid.sindex.intersection(geometry.bounds))\n",
    "    intersected_grid = grid.loc[tiles_indexes]\n",
    "    \n",
    "    # print(intersected_grid)\n",
    "\n",
    "    # Make the precise tiles in Polygon query\n",
    "    intersected_grid = intersected_grid.loc[grid.intersects(geometry)]\n",
    "\n",
    "    # intersection area\n",
    "    epsg = epsg_code(geometry.centroid.x, geometry.centroid.y)\n",
    "\n",
    "    # to UTM projection in meters\n",
    "    aoi.to_crs(epsg=epsg, inplace=True)\n",
    "    intersected_grid.to_crs(epsg=epsg, inplace=True)\n",
    "\n",
    "    return intersected_grid, epsg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _overlap_aoi_row(aoi, bbox_intersected, crs):\n",
    "    \n",
    "    result = list()\n",
    "\n",
    "    intersected = bbox_intersected.copy()\n",
    "    rest_aoi = gpd.GeoDataFrame([aoi], crs=crs)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        while rest_aoi.area.sum() > 0:\n",
    "       \n",
    "            res_intersection = gpd.overlay(rest_aoi, intersected, how=\"intersection\") # intersection area with tiles\n",
    "            biggest_area_id = res_intersection.area.argmax() # max intersected area\n",
    "            # print(\"res_intersection\")\n",
    "            # print(res_intersection)\n",
    "\n",
    "            tile_id = res_intersection.loc[biggest_area_id, \"Name\"]\n",
    "            intersected_aoi = res_intersection.loc[biggest_area_id, \"geometry\"]\n",
    "        \n",
    "            # print(tile_id)\n",
    "        \n",
    "            result.append({\"Name\": tile_id, \"geometry\": intersected_aoi}) # store max intersected aoi and tile geometry\n",
    "            biggest_tile = intersected.loc[intersected.Name == tile_id]\n",
    "\n",
    "            rest_aoi = gpd.overlay(rest_aoi, biggest_tile, how=\"difference\") # aoi minus biggest tile\n",
    "            intersected = intersected[intersected.Name != tile_id] # remove used tile\n",
    "    except Exception as ex:\n",
    "        print(f\"Error: {str(ex)}\")\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap(aoi, grid):\n",
    "    # first, find bbox intersection\n",
    "    bbox = box(*aoi.total_bounds)\n",
    "    bbox = gpd.GeoDataFrame(geometry=[box(*aoi.total_bounds)], crs=aoi.crs)\n",
    "    \n",
    "    bbox_intersected, epsg = _intersect(bbox, grid)\n",
    "    # print(bbox_intersected)\n",
    "    \n",
    "    # precise intersection\n",
    "    projected_aoi = aoi.copy().to_crs(epsg=epsg)\n",
    "    \n",
    "    results = list()\n",
    "    for row in projected_aoi.itertuples():\n",
    "        result = _overlap_aoi_row(row, bbox_intersected, projected_aoi.crs)\n",
    "        results.extend(result)\n",
    "        \n",
    "    return gpd.GeoDataFrame(results, crs=epsg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Planet images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planet_grid = gpd.read_file(os.path.join(BASE, \"notebooks/planet/planet_grid.geojson\"), driver=\"GeoJSON\")\n",
    "planet_grid.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planet_grid = filter_planet(planet_grid, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planet_grid = planet_grid[['id', 'acquired', 'geometry']].copy()\n",
    "planet_grid.rename(columns={\"id\": \"Name\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planet_grid.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planet_tiles = overlap(aoi, planet_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planet_tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planet_tiles = planet_tiles.merge(planet_grid[['Name', 'acquired']], on='Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planet_tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planet_tiles['date'] = planet_tiles.acquired.apply(lambda date:\n",
    "                                                   datetime.strptime(date, '%Y-%m-%dT%H:%M:%S').strftime('%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planet_tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(input_path, output_path, polygon, name=None, date=None):\n",
    "    with rasterio.open(input_path) as src:\n",
    "        out_image, out_transform = rasterio.mask.mask(src, [polygon], crop=True)\n",
    "        out_meta = src.meta\n",
    "                \n",
    "        out_meta.update({\"driver\": \"GTiff\",\n",
    "                 \"height\": out_image.shape[1],\n",
    "                 \"width\": out_image.shape[2],\n",
    "                 \"transform\": out_transform,\n",
    "                 \"nodata\": 0, \n",
    "                 })\n",
    "        \n",
    "        # if out_meta['dtype'] == 'uint16':\n",
    "        #    print(out_image)\n",
    "        #    print(f\"Image is in {out_meta['dtype']} type. Convert to uint8!\")\n",
    "        #    out_image = scale(out_image[0, :, :])\n",
    "            \n",
    "        #    out_image = out_image.astype(np.uint8)\n",
    "        #    scaled = out_image\n",
    "        #    out_meta.update({\"dtype\": rasterio.uint8, \"count\": 1})\n",
    "    \n",
    "        \n",
    "    # print(out_meta)\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    with rasterio.open(output_path, \"w\", **out_meta) as dest:\n",
    "        if name:\n",
    "            dest.update_tags(name=name)\n",
    "        if date:\n",
    "            dest.update_tags(start_date=date, end_date=date)\n",
    "        dest.write(out_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mosaic(files_to_mosaic, results_dir, name, start_date=None, end_date=None):\n",
    "    src_files_to_mosaic = list()\n",
    "    for fp in files_to_mosaic:\n",
    "        src = rasterio.open(fp)\n",
    "        src_files_to_mosaic.append(src)\n",
    "    \n",
    "    # crs of first input will be used\n",
    "    mosaic, out_trans = merge(src_files_to_mosaic)\n",
    "    out_meta = src.meta.copy()\n",
    "\n",
    "    # Update the metadata\n",
    "    out_meta.update({\"driver\": \"GTiff\",\n",
    "                     \"height\": mosaic.shape[1],\n",
    "                     \"width\": mosaic.shape[2],\n",
    "                     \"transform\": out_trans,\n",
    "                     })\n",
    "    \n",
    "    out_fp = os.path.join(results_dir, f\"{name}_mosaic.tif.temp\") \n",
    "    # print(out_fp)\n",
    "    os.makedirs(os.path.dirname(out_fp), exist_ok=True)\n",
    "    \n",
    "    with rasterio.open(out_fp, \"w\", **out_meta) as dest:\n",
    "        if name:\n",
    "            dest.update_tags(name=name)\n",
    "        if start_date:\n",
    "            dest.update_tags(start_date=start_date)\n",
    "        if end_date:\n",
    "            dest.update_tags(end_date=end_date)\n",
    "        dest.write(mosaic)\n",
    "        \n",
    "    os.rename(out_fp, out_fp[:-5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepair Planet images for AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start calculations...\")\n",
    "aoi_name = Path(aoi_path).stem\n",
    "for row in planet_tiles.itertuples():\n",
    "        \n",
    "    name = f\"{aoi_name}_{row.Name}\"\n",
    "        \n",
    "    input_path = os.path.join(IMGDIR, f\"PSScene/{row.Name}/visual/{row.Name}_3B_Visual.tif\")\n",
    "    print(input_path)\n",
    "    output_path = os.path.join(RESULTS_DIR, f\"{name}_planet_cropped.tif.temp\")\n",
    "    print(output_path)\n",
    "        \n",
    "    crop(input_path, output_path, row.geometry, name, row.date)\n",
    "    os.rename(output_path, output_path[:-5])\n",
    "    \n",
    "print(f\"Calculations finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Sentinel2 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentinel_grid_path = os.path.join(BASE, \"notebooks/planet/sentinel2grid.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentinel_grid = gpd.read_file(sentinel_grid_path)\n",
    "sentinel_grid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentinel_tiles = overlap(aoi, sentinel_grid)\n",
    "sentinel_tiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_dates(start_date, end_date, delta=5, format='%Y-%m-%d'):\n",
    "    start = datetime.strptime(start_date, format)\n",
    "    end = datetime.strptime(end_date, format)\n",
    "    \n",
    "    start = start - timedelta(days=delta)\n",
    "    end = end + timedelta(days=delta)\n",
    "    \n",
    "    return datetime.strftime(start, format), datetime.strftime(end, format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start, end = shift_dates(planet_tiles.date.min(), planet_tiles.date.max()) \n",
    "start, end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Sentinel2 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = os.path.join(BASE, \".secret/sentinel2_google_api_key.json\")\n",
    "LOAD_DIR = os.path.join(BASE, \"satellite_imagery\")\n",
    "\n",
    "\n",
    "BANDS = {'TCI', }\n",
    "CONSTRAINTS = {'NODATA_PIXEL_PERCENTAGE': 10.0, 'CLOUDY_PIXEL_PERCENTAGE': 5.0, }\n",
    "PRODUCT_TYPE = 'L2A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(api_key, tiles, start_date, end_date, output_dir, product_type=\"L2A\"):\n",
    "    loader = Sentinel2Downloader(api_key)\n",
    "    loadings = dict()\n",
    "    for tile in tiles:\n",
    "        print(f\"Loading images for tile: {tile}...\")\n",
    "        loaded = loader.download(product_type,\n",
    "                                 [tile],\n",
    "                                 start_date=start_date,\n",
    "                                 end_date=end_date,\n",
    "                                 output_dir=output_dir,                       \n",
    "                                 bands=BANDS,\n",
    "                                constraints=CONSTRAINTS)\n",
    "        \n",
    "        print(f\"Loading images for tile {tile} finished\")\n",
    "        loadings[tile] = loaded\n",
    "    \n",
    "    # tile_folders = dict()\n",
    "    # for tile, tile_paths in loadings.items():\n",
    "    #    tile_folders[tile] = {str(Path(tile_path[0]).parent) for tile_path in tile_paths}\n",
    "    return loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings = load_images(API_KEY, sentinel_tiles.Name.values, start, end, LOAD_DIR, PRODUCT_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_date(loadings):\n",
    "    def _find_last_date(folders):        \n",
    "        dates = list()\n",
    "        for folder in folders:        \n",
    "            search = re.search(r\"_(\\d+)T\\d+_\", str(folder))\n",
    "            date = search.group(1)\n",
    "            date = datetime.strptime(date, '%Y%m%d')\n",
    "            dates.append(date)    \n",
    "        last_date = max(dates)\n",
    "        last_date = datetime.strftime(last_date, '%Y%m%d')\n",
    "        return last_date\n",
    "    \n",
    "    filtered = dict()\n",
    "    for tile, items in loadings.items():\n",
    "        try:\n",
    "            last_date = _find_last_date(items)\n",
    "            for file, _ in items:\n",
    "                if \"TCI_10m.jp2\" in file and last_date in file:\n",
    "                    filtered[tile] = file\n",
    "        except Exception as ex:\n",
    "            print(f\"Error for {tile}: {str(ex)}\")\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = filter_date(loadings)\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not filtered:\n",
    "    raise ValueError(\"Images not loaded. Change dates or constraints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepair Sentinel2 images for AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.TemporaryDirectory(dir=WORKDIR) as tmpdirname:        \n",
    "    print(f\"Ð¡reated temporary directory for calculations: {tmpdirname}\")    \n",
    "    files_to_mosaic = list()\n",
    "    \n",
    "    aoi_name = Path(aoi_path).stem\n",
    "    for row in sentinel_tiles.itertuples():\n",
    "        \n",
    "        name = f\"{aoi_name}_{row.Name}_sentinel\"\n",
    "        \n",
    "        input_path = filtered[row.Name]        \n",
    "        output_path = os.path.join(tmpdirname, f\"{name}_cropped.tif\")\n",
    "        \n",
    "        crop(input_path, output_path, row.geometry)\n",
    "        files_to_mosaic.append(output_path)\n",
    "    \n",
    "    create_mosaic(files_to_mosaic, RESULTS_DIR, name)\n",
    "    print(f\"Calculations finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select (if needed) clearcuts from original file provided by V. Kharmtsov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_name = Path(aoi_path).stem\n",
    "clearcuts = gpd.read_file(\"original_clearcuts.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clearcuts.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clearcuts = clearcuts.loc[(clearcuts.img_date >= start_date) & \n",
    "                          (clearcuts.img_date <= end_date)]\n",
    "clearcuts.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_clearcuts = gpd.overlay(clearcuts, aoi, how=\"intersection\") \n",
    "aoi_clearcuts.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not aoi_clearcuts.empty:\n",
    "    aoi_clearcuts.to_file(os.path.join(WORKDIR, f\"{aoi_name}_clearcuts.geojson\"), driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
