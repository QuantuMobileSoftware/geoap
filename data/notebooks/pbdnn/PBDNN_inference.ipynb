{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AOI = 'POLYGON ((30.2759366834769 48.51505083641415, 30.61727452548106 48.45927941996875, 30.64285389693346 48.5330821966183, 30.30277405680401 48.58843427910546, 30.2759366834769 48.51505083641415))'\n",
    "START_DATE = \"2020-05-01\"\n",
    "END_DATE = \"2020-06-30\"\n",
    "\n",
    "REQUEST_ID = '6'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting boundaries for given AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import cv2\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import rasterio.mask\n",
    "import tempfile\n",
    "import shapely\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "from os.path import join, basename, split\n",
    "from skimage import measure\n",
    "from scipy.ndimage import rotate\n",
    "from rasterio.features import rasterize, shapes\n",
    "from rasterio.merge import merge\n",
    "from shapely.geometry import Polygon, shape, LinearRing\n",
    "import shapely.wkt\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import yaml\n",
    "import torch\n",
    "\n",
    "from sentinel2download.downloader import Sentinel2Downloader\n",
    "from sip_plot_boundary_detection_nn.code.preprocessing import (\n",
    "    preprocess_sentinel_raw_data, read_raster, extract_tci)\n",
    "from sip_plot_boundary_detection_nn.code.engine import load_model, val_tfs\n",
    "from sip_plot_boundary_detection_nn.code.dataset import BoundaryDetector\n",
    "from sip_plot_boundary_detection_nn.code.filter_polygons import filter_polygons\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_crs = 'EPSG:4326'\n",
    "\n",
    "polygon = shapely.wkt.loads(AOI)\n",
    "aoi_filename = f\"{time.time()}_aoi.geojson\"\n",
    "gpd.GeoDataFrame(gpd.GeoSeries([polygon]), columns=[\"geometry\"]).to_file(aoi_filename, driver=\"GeoJSON\")\n",
    "start_date = datetime.strptime(START_DATE, '%Y-%m-%d')\n",
    "end_date = datetime.strptime(END_DATE, '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tiles(aoi_path, sentinel_tiles_path):\n",
    "    '''\n",
    "    Returns Sentinel-2 tiles that intersects with specified AoI.\n",
    "\n",
    "        Parameters:\n",
    "            aoi_path (str): Path to geojson/shp file with AoI to process.\n",
    "            sentinel_tiles_path (str): Path to geojson/shp file with all Sentinel-2 tiles.\n",
    "\n",
    "        Returns:\n",
    "            date_tile_info (GeoDataFrame): Filtered tiles (tileID, geometry, date).\n",
    "    '''\n",
    "    aoi_file = gpd.read_file(aoi_path)\n",
    "    sentinel_tiles = gpd.read_file(sentinel_tiles_path)\n",
    "    sentinel_tiles.set_index(\"Name\", drop=False, inplace=True)\n",
    "\n",
    "    best_interseciton = {\"tileID\": [], \"geometry\": []}\n",
    "    rest_aoi = aoi_file.copy()\n",
    "\n",
    "    while rest_aoi.area.sum() > 0:\n",
    "        res_intersection = gpd.overlay(rest_aoi, sentinel_tiles, how=\"intersection\")\n",
    "        biggest_area_idx = res_intersection.area.argmax()\n",
    "\n",
    "        tileID = res_intersection.loc[biggest_area_idx, \"Name\"]\n",
    "        this_aoi = res_intersection.loc[biggest_area_idx, \"geometry\"]\n",
    "\n",
    "        best_interseciton[\"tileID\"].append(tileID)\n",
    "        best_interseciton[\"geometry\"].append(this_aoi)\n",
    "\n",
    "        biggest_intersection = sentinel_tiles.loc[[tileID]]\n",
    "        rest_aoi = gpd.overlay(rest_aoi, biggest_intersection, how=\"difference\")\n",
    "        sentinel_tiles = sentinel_tiles.loc[res_intersection[\"Name\"]]\n",
    "\n",
    "    date_tile_info = gpd.GeoDataFrame(best_interseciton)\n",
    "    date_tile_info.crs = aoi_file.crs\n",
    "    \n",
    "    return date_tile_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_polygons(result_df, current_crs, limit=500, dst_crs=\"EPSG:4326\"):\n",
    "    \"\"\"\n",
    "    Prepare result Dataframe with polygons\n",
    "\n",
    "        Parameters:\n",
    "            result_df (pd.DataFrame): Result DataFrame\n",
    "            limit (int): min area for polygon in m2\n",
    "        Returns:\n",
    "            GeoDataFrame: GeoDataFrame ready for saving\n",
    "    \"\"\"\n",
    "\n",
    "    gdf = gpd.GeoDataFrame(result_df)\n",
    "    gdf.crs = current_crs\n",
    "\n",
    "    gdf.to_crs(dst_crs, inplace=True)\n",
    "    return gdf\n",
    "\n",
    "\n",
    "def save_polygons(gdf, save_path):\n",
    "    if len(gdf) == 0:\n",
    "        return\n",
    "\n",
    "    directory = os.path.dirname(save_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "    gdf.to_file(save_path, driver='GeoJSON')\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find tile indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_USER = os.getenv('NB_USER')\n",
    "BASE = f\"/home/{NB_USER}/work\"\n",
    "\n",
    "API_KEY = os.path.join(BASE, \".secret/sentinel2_google_api_key.json\")\n",
    "LOAD_DIR = os.path.join(BASE, \"satellite_imagery\")\n",
    "RESULTS_DIR = os.path.join(BASE, \"results/pbdnn\")\n",
    "PBD_DIR = os.path.join(BASE, \"notebooks/pbdnn\")\n",
    "\n",
    "BANDS = {'TCI'}\n",
    "CONSTRAINTS = {'NODATA_PIXEL_PERCENTAGE': 15.0, 'CLOUDY_PIXEL_PERCENTAGE': 5.0, }\n",
    "PRODUCT_TYPE = 'L2A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local = False\n",
    "ukr_shapefile = os.path.join(BASE, \"data/notebooks/pbdnn/sip_plot_boundary_detection_nn/ukr_shapes/custom.geo.json\")\n",
    "if os.path.exists(ukr_shapefile):\n",
    "    usa_shapefile = os.path.join(BASE, \"data/notebooks/pbdnn/sip_plot_boundary_detection_nn/usa_shapes/custom.geo.json\")\n",
    "    config_file = os.path.join(BASE, \"data/notebooks/pbdnn/sip_plot_boundary_detection_nn/code/config.yaml\")\n",
    "    API_KEY = os.path.join(BASE, \"data/notebooks/pbdnn/sentinel2_google_api_key.json\")\n",
    "    PBD_DIR = os.path.join(BASE, \"data/notebooks/pbdnn\")\n",
    "    sentinel_tiles_path = os.path.join(BASE, \"data/notebooks/pbdnn/sentinel2grid.geojson\")\n",
    "    local = True\n",
    "else:\n",
    "    ukr_shapefile = os.path.join(BASE, \"notebooks/pbdnn/sip_plot_boundary_detection_nn/ukr_shapes/custom.geo.json\")\n",
    "    usa_shapefile = os.path.join(BASE, \"notebooks/pbdnn/sip_plot_boundary_detection_nn/usa_shapes/custom.geo.json\")\n",
    "    config_file = os.path.join(BASE, \"notebooks/pbdnn/sip_plot_boundary_detection_nn/code/config.yaml\")\n",
    "    sentinel_tiles_path = os.path.join(BASE, \"notebooks/pbdnn/sentinel2grid.geojson\")\n",
    "    local = False\n",
    "\n",
    "with open(config_file) as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check location before filtering non-agricultural lands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ukraine = gpd.read_file(ukr_shapefile)\n",
    "usa = gpd.read_file(usa_shapefile)\n",
    "aoi = gpd.read_file(aoi_filename)\n",
    "\n",
    "if local:\n",
    "    if aoi.intersects(ukraine)[0]:\n",
    "        filter_path = os.path.join(\n",
    "            BASE, \"data/notebooks/pbdnn/sip_plot_boundary_detection_nn/ukr_shapes/ukr_non_agriculture.geojson\")\n",
    "    elif aoi.intersects(usa)[0]:\n",
    "        filter_path = os.path.join(\n",
    "            BASE, \"data/notebooks/pbdnn/sip_plot_boundary_detection_nn/usa_shapes/us_shape.geojson\")\n",
    "    else:\n",
    "        filter_path = None\n",
    "else:\n",
    "    if aoi.intersects(ukraine)[0]:\n",
    "        filter_path = os.path.join(\n",
    "            BASE, \"notebooks/pbdnn/sip_plot_boundary_detection_nn/ukr_shapes/ukr_non_agriculture.geojson\")\n",
    "    elif aoi.intersects(usa)[0]:\n",
    "        filter_path = os.path.join(\n",
    "            BASE, \"notebooks/pbdnn/sip_plot_boundary_detection_nn/usa_shapes/us_shape.geojson\")\n",
    "    else:\n",
    "        filter_path = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_folder(tile_folder, file, limit, nodata):\n",
    "    with rasterio.open(os.path.join(tile_folder, file)) as src:              \n",
    "        # Read in image as a numpy array\n",
    "        array = src.read(1)\n",
    "        # Count the occurance of NoData values in np array\n",
    "        nodata_count = np.count_nonzero(array == nodata)\n",
    "        # Get a % of NoData pixels\n",
    "        nodata_percentage = round(nodata_count / array.size * 100, 2)\n",
    "        if nodata_percentage <= limit:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_nodata(loadings, product_type, limit=15.0, nodata=0):\n",
    "    filtered = dict()          \n",
    "    \n",
    "    for tile, folders in loadings.items():\n",
    "        filtered_folders = set()\n",
    "        for folder in folders:\n",
    "            for file in os.listdir(folder):\n",
    "                if file.endswith(\".jp2\") and \"OPER\" not in file:\n",
    "                    if product_type == 'L1C' and limit:\n",
    "                         if _check_folder(folder, file, limit, nodata):\n",
    "                            filtered_folders.add(folder)\n",
    "                            break\n",
    "                    else:\n",
    "                        filtered_folders.add(folder)\n",
    "        filtered[tile] = filtered_folders\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = r'\\<CLOUDY_PIXEL_PERCENTAGE\\>[0-9]*\\.?[0-9]*</CLOUDY_PIXEL_PERCENTAGE>'\n",
    "\n",
    "def get_min_clouds(loadings, max_ptc=5):\n",
    "    filtered = dict()\n",
    "    min_ptc = max_ptc\n",
    "    \n",
    "    for tile, folders in loadings.items():\n",
    "        filtered_folders = set()\n",
    "        for folder in folders:\n",
    "            for file in os.listdir(folder):\n",
    "                \n",
    "                if \"MTD_TL.xml\" in file:\n",
    "                    \n",
    "                    with open(os.path.join(folder, file)) as f:\n",
    "                        ptc = f.read()\n",
    "                        ptc = re.search(regex, ptc)\n",
    "                        \n",
    "                        if ptc is not None:\n",
    "                            ptc = ''.join([x for x in ptc.group(0) if x.isdigit() or x=='.'])\n",
    "                            # print(ptc)\n",
    "                            filtered_folders.add((ptc, folder))\n",
    "    \n",
    "        filtered[tile] = sorted(filtered_folders)[0][1]\n",
    "\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(api_key, tiles, start_date, end_date, output_dir, product_type=\"L2A\"):\n",
    "    loader = Sentinel2Downloader(api_key)\n",
    "    loadings = dict()\n",
    "    for tile in tiles:\n",
    "\n",
    "        loaded = loader.download(product_type,\n",
    "                                 [tile],\n",
    "                                 start_date=start_date,\n",
    "                                 end_date=end_date,\n",
    "                                 output_dir=output_dir,                       \n",
    "                                 bands=BANDS,\n",
    "                                constraints=CONSTRAINTS)\n",
    "        print(f'{tile} loaded')\n",
    "        \n",
    "        loadings[tile] = loaded\n",
    "    \n",
    "    tile_folders = dict()\n",
    "    for tile, tile_paths in loadings.items():\n",
    "        tile_folders[tile] = {str(Path(tile_path[0]).parent) for tile_path in tile_paths}\n",
    "    return tile_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit for baseline: work/notebooks/pw/raster_predict.ipynb\n",
    "def create_style():\n",
    "    style = {'color': '#C0C0C0', 'stroke': 'e80e27', 'stroke-width': 2}\n",
    "\n",
    "    return str(style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['device'] = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "if local:\n",
    "    model_path = os.path.join(\n",
    "        BASE, 'data/notebooks/pbdnn/sip_plot_boundary_detection_nn/models/UnetPlusPlus_imagenet_30_denmark_filtered.pth')\n",
    "else:\n",
    "    model_path = os.path.join(\n",
    "        BASE, 'notebooks/pbdnn/sip_plot_boundary_detection_nn/models/UnetPlusPlus_imagenet_30_denmark_filtered.pth')\n",
    "\n",
    "model = load_model(config['model'].lower(), model_path, config['device'])\n",
    "    \n",
    "print('Model loaded successfully')\n",
    "    \n",
    "date_tile_info = get_tiles(aoi_filename, sentinel_tiles_path)\n",
    "loadings = load_images(API_KEY, date_tile_info.tileID.values, START_DATE, END_DATE, LOAD_DIR, PRODUCT_TYPE)\n",
    "checked = check_nodata(loadings, PRODUCT_TYPE)\n",
    "\n",
    "checked = get_min_clouds(checked)\n",
    "\n",
    "origin_name = os.path.basename(aoi_filename).replace(\".geojson\", \"\")\n",
    "\n",
    "print(f'total tiles: {len(loadings)}')\n",
    "\n",
    "detector = BoundaryDetector(model, tiles_dir=f'/home/{NB_USER}/work/satellite_imagery')\n",
    "print('Detector is ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame([])\n",
    "\n",
    "if filter_path is not None:\n",
    "    filters = gpd.read_file(filter_path)\n",
    "    aoi = gpd.read_file(aoi_filename).to_crs(filters.crs)\n",
    "            \n",
    "    if 'ukr_non_agriculture' in filter_path:\n",
    "        filters['geometry'] = filters.buffer(0)\n",
    "            \n",
    "    filters = filters[filters.intersects(aoi.geometry.values[0])]\n",
    "    print('filters are loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch_tiles(paths, out_raster_path='test.tif'):\n",
    "    tiles = []\n",
    "    \n",
    "    for i, path in enumerate(paths):\n",
    "        file = rasterio.open(path)\n",
    "        tiles.append(file)\n",
    "            \n",
    "        \n",
    "    tile_arr, transform = merge(tiles, method='last')\n",
    "    meta, crs = file.meta, file.crs\n",
    "    \n",
    "    meta.update({\"driver\": \"GTiff\",\n",
    "                 \"height\": tile_arr.shape[1],\n",
    "                 \"width\": tile_arr.shape[2],\n",
    "                 \"transform\": transform,\n",
    "                 \"crs\": crs})\n",
    "    \n",
    "    if '.jp2' in out_raster_path:\n",
    "        out_raster_path = out_raster_path.replace('.jp2', '_merged.tif')\n",
    "    else:\n",
    "        out_raster_path = out_raster_path.replace('.tif', '_merged.tif')\n",
    "    print(f'saved raster {out_raster_path}')\n",
    "\n",
    "    for tile in tiles:\n",
    "        tile.close()\n",
    "        \n",
    "    with rasterio.open(out_raster_path, \"w\", **meta) as dst:\n",
    "        dst.write(tile_arr)\n",
    "    \n",
    "    return out_raster_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running boundary detection and filtration of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rasters = []\n",
    "for i, tile in date_tile_info.iterrows():\n",
    "    try:\n",
    "        tile_folder = Path(checked[tile.tileID])\n",
    "        print(f'checked: {tile_folder}')\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        continue\n",
    "        \n",
    "    full_tile = [os.path.join(tile_folder, filename) for filename in os.listdir(tile_folder) if 'TCI_10m.jp2' in filename]\n",
    "    rasters.append(full_tile[0])\n",
    "        \n",
    "print(f'rasters to be processed: {rasters}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(rasters)>1:\n",
    "    raster_path = stitch_tiles(rasters)\n",
    "elif len(rasters)==1:\n",
    "    raster_path = rasters[0]\n",
    "elif len(rasters)==0:\n",
    "    print('WARNING: no rasters were found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '.jp2' in raster_path:\n",
    "    out_raster = raster_path.replace('.jp2', '_prediction.tif')\n",
    "else:\n",
    "    out_raster = raster_path.replace('.tif', '_prediction.tif')\n",
    "    \n",
    "out_geom = aoi_filename.replace('_aoi.', '_prediction.')\n",
    "        \n",
    "pred_tif_path = detector.raster_prediction(in_raster_path=raster_path,\n",
    "                                            out_raster_path=out_raster,\n",
    "                                            aoi_path=aoi_filename,\n",
    "                                            conf_thresh=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons = detector.process_raster_predictions(pred_tif_path,\n",
    "                                                shapes_path=out_geom,\n",
    "                                                aoi_path=aoi_filename, \n",
    "                                                conf_thresh=0.25)\n",
    "polygons = gpd.GeoDataFrame(polygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(filters) != 0:\n",
    "    try:\n",
    "        polys = filter_polygons(polygons, filters)\n",
    "    except Exception as e:\n",
    "        print(e, '\\n', 'fixing geometries...')\n",
    "        filters['geometry'] = filters.buffer(0)\n",
    "        polys = filter_polygons(polygons, filters)\n",
    "else:\n",
    "    print('Non-agricultural data is not found for a given AOI, proceeding without filtering')\n",
    "    polys = polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"geometry\": polys.geometry}).reset_index()\n",
    "df[\"id\"] = pd.Series(map(lambda x: f\"{origin_name}_{tile.tileID}_{x}\", df.index.values))\n",
    "df[\"tileID\"] = tile.tileID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.concat([result_df, df])\n",
    "gdf = process_polygons(result_df, filters.crs)\n",
    "gdf.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving polygons into results folder and adding metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-14T07:33:11.813667Z",
     "iopub.status.busy": "2021-04-14T07:33:11.813347Z",
     "iopub.status.idle": "2021-04-14T07:33:11.819019Z",
     "shell.execute_reply": "2021-04-14T07:33:11.818743Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp_suffix = \".temp\"\n",
    "gdf['style'] = create_style()\n",
    "save_path = os.path.join(RESULTS_DIR, f\"{REQUEST_ID}_{START_DATE}_{END_DATE}.geojson{tmp_suffix}\")\n",
    "save_polygons(gdf, save_path)\n",
    "\n",
    "try:\n",
    "    with open(save_path) as file:\n",
    "        geoms = json.load(file)\n",
    "except Exception:\n",
    "    geoms = {}\n",
    "    \n",
    "geoms['end_date'] = END_DATE\n",
    "geoms['start_date'] = START_DATE\n",
    "geoms['name'] = \"Fields' boundaries\"\n",
    "geoms['request_id'] = REQUEST_ID\n",
    "\n",
    "with open(save_path, 'w') as file:\n",
    "    json.dump(geoms, file)\n",
    "os.rename(save_path, save_path[:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-14T07:33:11.820922Z",
     "iopub.status.busy": "2021-04-14T07:33:11.820609Z",
     "iopub.status.idle": "2021-04-14T07:33:11.823326Z",
     "shell.execute_reply": "2021-04-14T07:33:11.823002Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.remove(aoi_filename)\n",
    "except FileNotFoundError:\n",
    "    print('No helping geojson files were generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-14T07:33:11.825303Z",
     "iopub.status.busy": "2021-04-14T07:33:11.824989Z",
     "iopub.status.idle": "2021-04-14T07:33:11.830533Z",
     "shell.execute_reply": "2021-04-14T07:33:11.830210Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.remove(out_raster)\n",
    "except FileNotFoundError:\n",
    "    print('No helping raster files were generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-14T07:33:11.832557Z",
     "iopub.status.busy": "2021-04-14T07:33:11.832246Z",
     "iopub.status.idle": "2021-04-14T07:33:11.837465Z",
     "shell.execute_reply": "2021-04-14T07:33:11.837739Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.remove(pred_tif_path)\n",
    "except FileNotFoundError:\n",
    "    print('No helping prediction raster found, skipping')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
