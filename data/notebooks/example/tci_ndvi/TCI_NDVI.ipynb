{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For given aoi, prepare TCI and NDVI sentinel latest images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AOI = 'POLYGON ((-85.299088 40.339368, -85.332047 40.241477, -85.134979 40.229427, -85.157639 40.34146, -85.299088 40.339368))' \n",
    "REQUEST_ID = 51\n",
    "START_DATE = \"2020-07-01\"\n",
    "END_DATE = \"2020-08-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gp\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import re\n",
    "import tempfile\n",
    "import pyproj\n",
    "import uuid\n",
    "import json\n",
    "import geojson\n",
    "\n",
    "from geojson import Feature\n",
    "\n",
    "import rasterio.mask\n",
    "from rasterio import Affine\n",
    "from rasterio.plot import reshape_as_raster\n",
    "from rasterio.merge import merge\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "\n",
    "from shapely import wkt\n",
    "from shapely.geometry import Polygon, box\n",
    "from shapely.ops import transform\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from sentinel2download.downloader import Sentinel2Downloader\n",
    "from sentinel2download.overlap import Sentinel2Overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Setting-up folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Transform AOI and get bound_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi = gp.GeoDataFrame(geometry=[wkt.loads(AOI)], crs=\"epsg:4326\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ð¡reate base path, usually env=jovyan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = f\"/home/{os.getenv('NB_USER')}/work\"\n",
    "BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentinel_grid = gp.read_file(\"sentinel2grid.geojson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Overlap AOI with sentinel2grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsg_code(longitude, latitude):\n",
    "        \"\"\"\n",
    "        Generates EPSG code from lon, lat\n",
    "        :param longitude: float\n",
    "        :param latitude: float\n",
    "        :return: int, EPSG code\n",
    "        \"\"\"\n",
    "\n",
    "        def _zone_number(lat, lon):\n",
    "            if 56 <= lat < 64 and 3 <= lon < 12:\n",
    "                return 32\n",
    "            if 72 <= lat <= 84 and lon >= 0:\n",
    "                if lon < 9:\n",
    "                    return 31\n",
    "                elif lon < 21:\n",
    "                    return 33\n",
    "                elif lon < 33:\n",
    "                    return 35\n",
    "                elif lon < 42:\n",
    "                    return 37\n",
    "\n",
    "            return int((lon + 180) / 6) + 1\n",
    "\n",
    "        zone = _zone_number(latitude, longitude)\n",
    "\n",
    "        if latitude > 0:\n",
    "            return 32600 + zone\n",
    "        else:\n",
    "            return 32700 + zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _intersect(aoi, grid):\n",
    "    # Get the indices of the tiles that are likely to be inside the bounding box of the given Polygon\n",
    "    geometry = aoi.geometry[0]\n",
    "\n",
    "    tiles_indexes = list(grid.sindex.intersection(geometry.bounds))\n",
    "    grid = grid.loc[tiles_indexes]\n",
    "\n",
    "    # Make the precise tiles in Polygon query\n",
    "    grid = grid.loc[grid.intersects(geometry)]\n",
    "\n",
    "    # intersection area\n",
    "    epsg = epsg_code(geometry.centroid.x, geometry.centroid.y)\n",
    "\n",
    "    # to UTM projection in meters\n",
    "    aoi.to_crs(epsg=epsg, inplace=True)\n",
    "    grid.to_crs(epsg=epsg, inplace=True)\n",
    "\n",
    "    return grid, epsg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intersected_tiles(aoi, grid):\n",
    "    \n",
    "    grid, epsg = _intersect(aoi, sentinel_grid)\n",
    "    \n",
    "    \n",
    "    grid.set_index(\"Name\", drop=False, inplace=True)    \n",
    "    intersected_grid = {\"tile\": [], \"geometry\": []}\n",
    "\n",
    "    rest_aoi = aoi.copy()\n",
    "    while rest_aoi.area.sum() > 0:\n",
    "        intersection = gp.overlay(rest_aoi, grid, how=\"intersection\")\n",
    "        argmax = intersection.area.argmax()\n",
    "\n",
    "        tile = intersection.loc[argmax, \"Name\"]\n",
    "        intersected_geometry = intersection.loc[argmax, \"geometry\"]\n",
    "        \n",
    "        intersected_grid[\"tile\"].append(tile)\n",
    "        intersected_grid[\"geometry\"].append(intersected_geometry)\n",
    "        \n",
    "        biggest_intersection = grid.loc[[tile]]\n",
    "        rest_aoi = gp.overlay(rest_aoi, biggest_intersection, how=\"difference\")\n",
    "        grid = grid.loc[intersection[\"Name\"]]\n",
    "    \n",
    "    overlap_tiles = gp.GeoDataFrame(intersected_grid, crs=epsg)\n",
    "    overlap_tiles.to_crs(epsg=4326, inplace=True)\n",
    "\n",
    "    return overlap_tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_tiles = get_intersected_tiles(aoi.copy(), sentinel_grid.copy())\n",
    "overlap_tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_tiles.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = SENTINEL2_GOOGLE_API_KEY\n",
    "LOAD_DIR = os.path.join(BASE, \"satellite_imagery\")\n",
    "\n",
    "PRODUCT_TYPE = 'L2A'\n",
    "BANDS = {'TCI', 'B04', 'B08', }\n",
    "CONSTRAINTS = {'NODATA_PIXEL_PERCENTAGE': 10.0, 'CLOUDY_PIXEL_PERCENTAGE': 5.0, }\n",
    "\n",
    "LAYERS = ['TCI', 'NDVI', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "END_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_date(date, delta=5, format='%Y-%m-%d'):\n",
    "    date = datetime.strptime(date, format)\n",
    "    date = date - timedelta(days=delta)    \n",
    "    return datetime.strftime(date, format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Define max shift in dates - 30 days for loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SHIFT = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SHIFT_ITERS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(tiles, start_date, end_date):\n",
    "    loader = Sentinel2Downloader(API_KEY)\n",
    "    \n",
    "    loadings = dict()\n",
    "        \n",
    "    for tile in tiles:\n",
    "        start = start_date\n",
    "        end = end_date\n",
    "        \n",
    "        print(f\"Loading images for tile: {tile}...\")\n",
    "        count = 0\n",
    "        while count < MAX_SHIFT_ITERS:\n",
    "            loaded = loader.download(PRODUCT_TYPE,\n",
    "                                [tile],\n",
    "                                start_date=start,\n",
    "                                end_date=end,\n",
    "                                output_dir=LOAD_DIR,                       \n",
    "                                bands=BANDS,\n",
    "                                constraints=CONSTRAINTS)\n",
    "        \n",
    "            if not loaded:\n",
    "                end = start_date\n",
    "                start = shift_date(start_date, delta=MAX_SHIFT) \n",
    "                print(f\"For tile: {tile} and dates {start_date} {end_date} proper images not found! Shift dates to {start} {end}!\")\n",
    "            else:\n",
    "                break\n",
    "            count += 1\n",
    "        if loaded:\n",
    "            loadings[tile] = loaded\n",
    "            print(f\"Loading images for tile {tile} finished\")\n",
    "        else:\n",
    "            print(f\"Images for tile {tile} were not loaded!\")\n",
    "        \n",
    "    # tile_folders = dict()\n",
    "    # for tile, tile_paths in loadings.items():\n",
    "    #    tile_folders[tile] = {str(Path(tile_path[0]).parent) for tile_path in tile_paths}\n",
    "    return loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings = load_images(overlap_tiles.tile.values, START_DATE, END_DATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Filter loadings for every tile, get last image in daterange and bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_date(loadings):\n",
    "    def _find_last_date(folders):        \n",
    "        dates = list()\n",
    "        for folder in folders:        \n",
    "            search = re.search(r\"_(\\d+)T\\d+_\", str(folder))\n",
    "            date = search.group(1)\n",
    "            date = datetime.strptime(date, '%Y%m%d')\n",
    "            dates.append(date)    \n",
    "        last_date = max(dates)\n",
    "        last_date = datetime.strftime(last_date, '%Y%m%d')\n",
    "        return last_date\n",
    "    \n",
    "    filtered = dict()\n",
    "    for tile, items in loadings.items():\n",
    "        try:\n",
    "            last_date = _find_last_date(items)\n",
    "            bands_paths = dict()\n",
    "            for path, _ in items:\n",
    "                if last_date in path:\n",
    "                    if 'B04_10m.jp2' in path:\n",
    "                        bands_paths['RED'] = path\n",
    "                    if 'B08_10m.jp2' in path:\n",
    "                        bands_paths['NIR'] = path\n",
    "                    if 'TCI_10m.jp2' in path:\n",
    "                        bands_paths['TCI'] = path\n",
    "            filtered[tile] = dict(paths=bands_paths, date=last_date)\n",
    "        except Exception as ex:\n",
    "            print(f\"Error for {tile}: {str(ex)}\")\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = filter_by_date(loadings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Calculate NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = OUTPUT_FOLDER\n",
    "\n",
    "NOTEBOOK_DIR = os.path.join(RESULTS_DIR, \"notebook\")\n",
    "COLORMAP_BRBG = os.path.join(NOTEBOOK_DIR, \"ndvi_colormap.npy\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Prepare color coding for NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_colors(colors):\n",
    "    colors = np.load(COLORMAP_BRBG)\n",
    "    if colors.shape[1] == 4:\n",
    "        # delete last channel, we use rgb\n",
    "        colors = np.delete(colors, 3, axis=1)\n",
    "    # colormap colors values in range [0-255], but in our case 0 - no data, -> have to color as [0, 0, 0] \n",
    "    colors[colors == 0] = 1\n",
    "    colors[0] = [0, 0, 0]\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = prepare_colors(COLORMAP_BRBG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap_tag = {\"name\": \"Vegetation index\", \"colors\": [], \"labels\": [\"low\", \"high\"]}\n",
    "\n",
    "for color in COLORS:\n",
    "    color_str = \",\".join(list(map(lambda x: str(int(x)), color)))\n",
    "    colormap_tag['colors'].append(color_str)\n",
    "\n",
    "colormap_tag = json.dumps(colormap_tag)\n",
    "# example of colormap_tag format\n",
    "# {\"name\": \"Vegetation index\", \"colors\": [\"0,0,0\", \"255,0,0\", \"0,255,0\", \"0,0,255\" ...], \"labels\": [\"low\", \"high\"]}\n",
    "colormap_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(ndvi, a=1, b=255, nodata=0.0):\n",
    "    # ndvi is in range [-1; 1], nodata is setted to 0.0 value. Be careful with comprassions!\n",
    "    min = -1 # np.nanmin(ndvi)\n",
    "    max = 1 # np.nanmax(ndvi)\n",
    "    scaled = (b - a) * (ndvi - min) / (max - min) + a\n",
    "    scaled = np.around(scaled)\n",
    "    scaled[np.isnan(scaled) == True] = nodata\n",
    "    scaled = scaled.astype(np.uint8)\n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_ndvi(scaled, colors):\n",
    "    colored = np.reshape(colors[scaled.flatten()], tuple((*scaled.shape, 3)))\n",
    "    colored = reshape_as_raster(colored)\n",
    "    return colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NDVI(nir_path, red_path, save_path):\n",
    "    # Asllow division by zero\n",
    "    np.seterr(divide='ignore', invalid='ignore')\n",
    "    \n",
    "    with rasterio.open(nir_path) as src:\n",
    "        nir = src.read(1).astype(rasterio.float32)\n",
    "        crs = str(src.crs)\n",
    "    with rasterio.open(red_path) as src:\n",
    "        red = src.read(1).astype(rasterio.float32)\n",
    "\n",
    "    # Calculate NDVI\n",
    "    ndvi = ((nir - red) / (nir + red)) \n",
    "    \n",
    "    scaled = scale(ndvi)\n",
    "    colored = color_ndvi(scaled, COLORS) \n",
    "    \n",
    "    \n",
    "    # Set spatial characteristics of the output object\n",
    "    out_meta = src.meta.copy()    \n",
    "    out_meta.update(dtype=rasterio.uint8,\n",
    "                    driver='GTiff',\n",
    "                    nodata=0,\n",
    "                    count=3, )\n",
    "\n",
    "    # Create the file\n",
    "    with rasterio.open(save_path, 'w', **out_meta) as dst:\n",
    "         dst.write(colored)\n",
    "    return crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_crs(poly, target, current='EPSG:4326'):\n",
    "    # print(f\"TARGET CRS: {target}\")\n",
    "    project = pyproj.Transformer.from_crs(pyproj.CRS(current), pyproj.CRS(target), always_xy=True).transform\n",
    "    transformed_poly = transform(project, poly)\n",
    "    return transformed_poly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(input_path, output_path, polygon, date, request_id, name=None, colormap=None):\n",
    "    with rasterio.open(input_path) as src:\n",
    "        out_image, out_transform = rasterio.mask.mask(src, [polygon], crop=True)\n",
    "        # print(out_transform)\n",
    "        out_meta = src.meta\n",
    "        \n",
    "        out_meta.update(driver='GTiff',\n",
    "                        height=out_image.shape[1],\n",
    "                        width=out_image.shape[2],\n",
    "                        transform=out_transform,\n",
    "                        nodata=0, )\n",
    "\n",
    "    with rasterio.open(output_path, \"w\", **out_meta) as dest:\n",
    "        dest.update_tags(start_date=date, end_date=date, request_id=request_id)\n",
    "        if name:\n",
    "            dest.update_tags(name=name)\n",
    "        if colormap:\n",
    "            dest.update_tags(colormap=colormap)\n",
    "        dest.write(out_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_crs(data_path, save_path, dst_crs=\"EPSG:4326\", resolution=(10, 10)):\n",
    "    with rasterio.open(data_path) as src:\n",
    "        if resolution is None:\n",
    "            transform, width, height = calculate_default_transform(\n",
    "                src.crs, dst_crs, src.width, src.height, *src.bounds\n",
    "            )\n",
    "        else:\n",
    "            transform, width, height = calculate_default_transform(\n",
    "                src.crs,\n",
    "                dst_crs,\n",
    "                src.width,\n",
    "                src.height,\n",
    "                *src.bounds,\n",
    "                resolution=resolution,\n",
    "            )\n",
    "        kwargs = src.meta.copy()\n",
    "        kwargs.update(\n",
    "            {\"crs\": dst_crs, \"transform\": transform, \"width\": width, \"height\": height}\n",
    "        )\n",
    "        with rasterio.open(save_path, \"w\", **kwargs) as dst:\n",
    "            for i in range(1, src.count + 1):\n",
    "                reproject(\n",
    "                    source=rasterio.band(src, i),\n",
    "                    destination=rasterio.band(dst, i),\n",
    "                    src_transform=src.transform,\n",
    "                    src_crs=src.crs,\n",
    "                    dst_transform=transform,\n",
    "                    dst_crs=dst_crs,\n",
    "                    resampling=Resampling.nearest,\n",
    "                )\n",
    "\n",
    "    return save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch_tiles(paths, out_raster_path, date, request_id, name=None, colormap=None):\n",
    "    if not isinstance(paths[0], str):\n",
    "        paths = [str(x) for x in paths]\n",
    "    tiles = []\n",
    "    tmp_files = []\n",
    "    \n",
    "    crs = None\n",
    "    meta = None\n",
    "    for i, path in enumerate(paths):\n",
    "        if i == 0:\n",
    "            file = rasterio.open(path)\n",
    "            meta, crs = file.meta, file.crs\n",
    "        else:\n",
    "            tmp_path = path.replace(\n",
    "                '.jp2', '_tmp.jp2').replace('.tif', '_tmp.tif')\n",
    "            crs_transformed = transform_crs(path, tmp_path, \n",
    "                                            dst_crs=crs, \n",
    "                                            resolution=None)\n",
    "            tmp_files.append(crs_transformed)\n",
    "            file = rasterio.open(crs_transformed)\n",
    "        tiles.append(file)\n",
    "            \n",
    "    tile_arr, transform = merge(tiles, method='last')\n",
    "    \n",
    "    meta.update({\"driver\": \"GTiff\",\n",
    "                 \"height\": tile_arr.shape[1],\n",
    "                 \"width\": tile_arr.shape[2],\n",
    "                 \"transform\": transform,\n",
    "                 \"crs\": crs})\n",
    "    \n",
    "    if '.jp2' in out_raster_path:\n",
    "        out_raster_path = out_raster_path.replace('.jp2', '.tif')\n",
    "    print(f'saved raster {out_raster_path}')\n",
    "\n",
    "    for tile in tiles:\n",
    "        tile.close()\n",
    "        \n",
    "    for tmp_file in tmp_files:\n",
    "        try:\n",
    "            os.remove(tmp_file)\n",
    "        except FileNotFoundError:\n",
    "            print(f'Tile {tmp_file} was removed or renamed, skipping')\n",
    "        \n",
    "    with rasterio.open(out_raster_path, \"w\", **meta) as dst:\n",
    "        dst.update_tags(start_date=date, end_date=date, request_id=request_id)\n",
    "        if name:\n",
    "            dst.update_tags(name=name)\n",
    "        if colormap:\n",
    "            dst.update_tags(colormap=colormap)\n",
    "        dst.write(tile_arr)\n",
    "    \n",
    "    return out_raster_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_no_data_geosjon(polygon, geojson_path):\n",
    "    NO_DATA = 'No data'\n",
    "    TCI_NDVI_NO_DATA = 'TCI_NDVI\\nNo data available'\n",
    "    style = dict(color='red')\n",
    "    feature = Feature(geometry=polygon, properties=dict(label=NO_DATA, style=style))\n",
    "    feature['start_date'] = START_DATE\n",
    "    feature['end_date'] = END_DATE\n",
    "    feature['request_id'] = REQUEST_ID\n",
    "    feature['name'] = TCI_NDVI_NO_DATA\n",
    "    \n",
    "    with open(geojson_path, 'w') as f:\n",
    "        geojson.dump(feature, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Calculate and crop NDVI, TCI\n",
    "\n",
    "#### Filenames have next names: REQUESTID_TILE_ID_ACQUIREDDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESULTS_DIR = os.path.join(RESULTS_DIR, str(REQUEST_ID))\n",
    "# RESULTS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "if not filtered:\n",
    "    geojson_path = os.path.join(RESULTS_DIR, \"aoi.geojson\")\n",
    "    dump_no_data_geosjon(aoi.geometry[0], geojson_path)    \n",
    "    raise ValueError(\"Images not loaded for given AOI. Change dates, constraints\")\n",
    "\n",
    "\n",
    "tci_images = []\n",
    "ndvi_images = []\n",
    "for row in overlap_tiles.itertuples():\n",
    "    tile = row.tile\n",
    "    polygon = row.geometry\n",
    "    if not tile in filtered:\n",
    "        tile_geojson_path = os.path.join(RESULTS_DIR, \"%s_aoi.geojson\" % tile)\n",
    "        print(\"No data loaded for tile\", tile)\n",
    "        dump_no_data_geosjon(polygon, tile_geojson_path)    \n",
    "    \n",
    "    try:\n",
    "        paths = filtered[tile]['paths']\n",
    "        print(f\"{tile}: Start calculation TCI, NDVI\")\n",
    "        \n",
    "        acquired_date = filtered[tile]['date']\n",
    "        base_filename = f\"{REQUEST_ID}_{tile}_{acquired_date}_\"\n",
    "        temp_ndvi_filename = os.path.join(RESULTS_DIR, base_filename + \"NDVI.tif.temp\")\n",
    "        temp_tci_filename = os.path.join(RESULTS_DIR, base_filename + \"TCI.tif.temp\")\n",
    "        \n",
    "        tile_crs = NDVI(paths['NIR'], paths['RED'], temp_ndvi_filename)\n",
    "        transformed_poly = to_crs(polygon, tile_crs)\n",
    "        \n",
    "        # Crop and save NDVI\n",
    "        crop(temp_ndvi_filename, temp_ndvi_filename, transformed_poly, acquired_date, REQUEST_ID, name=\"Sentinel-2 Vegetation Index (NDVI)\", colormap=colormap_tag)\n",
    "        # Crop and save TCI\n",
    "        crop(paths['TCI'], temp_tci_filename, transformed_poly, acquired_date, REQUEST_ID, name=\"Sentinel-2 RGB raster\")\n",
    "        \n",
    "        print(f\"{tile}: End calculation TCI, NDVI\")\n",
    "    \n",
    "        ndvi_filename = temp_ndvi_filename[:-5]\n",
    "        tci_filename = temp_tci_filename[:-5]\n",
    "        print(f\"{tile}: Rename {temp_ndvi_filename}->{ndvi_filename}\\n {temp_tci_filename}->{tci_filename}\")\n",
    "        os.rename(temp_ndvi_filename, ndvi_filename)\n",
    "        os.rename(temp_tci_filename, tci_filename)\n",
    "        tci_images.append(tci_filename)\n",
    "        ndvi_images.append(ndvi_filename)\n",
    "    except Exception as e:\n",
    "        print(f\"{tile}: Cannot calculate TCI, NDVI: {str(e)}\")\n",
    "\n",
    "if len(tci_images) > 1:\n",
    "    base_filename = f\"{REQUEST_ID}_{'-'.join(filtered.keys())}_{acquired_date}\"\n",
    "    tci_full = stitch_tiles(tci_images, os.path.join(RESULTS_DIR, base_filename + \"_TCI.tif\"), acquired_date, REQUEST_ID, name=\"Sentinel-2 RGB raster\")\n",
    "    ndvi_full = stitch_tiles(ndvi_images, os.path.join(RESULTS_DIR, base_filename + \"_NDVI.tif\"), acquired_date, REQUEST_ID, name=\"Sentinel-2 Vegetation Index (NDVI)\", colormap=colormap_tag)\n",
    "    for i in range(len(tci_images)):\n",
    "        os.remove(tci_images[i])\n",
    "        os.remove(ndvi_images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "50edd631a3a560ea7324d5c52966dd3e43b748ed4c5045c62a87154f45d21dc5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
