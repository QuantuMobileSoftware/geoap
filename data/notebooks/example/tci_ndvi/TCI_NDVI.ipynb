{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For given aoi, prepare TCI and NDVI sentinel latest images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AOI = 'POLYGON ((35.4638671875000000 50.4365160169863316, 34.6618652343750000 50.0289165635219035, 34.7827148437500000 48.9549736980886792, 36.3757324218749929 48.3781454697624440, 37.4194335937500000 48.7851519980431547, 38.3038330078125000 49.4431287580300491, 37.9193115234374929 50.4120182466821731, 36.6009521484375000 50.5553249825196716, 35.4638671875000000 50.4365160169863316))' \n",
    "REQUEST_ID = 10\n",
    "START_DATE = \"2020-08-01\"\n",
    "END_DATE = \"2020-08-10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gp\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import re\n",
    "import tempfile\n",
    "import pyproj\n",
    "import uuid\n",
    "\n",
    "import rasterio.mask\n",
    "from rasterio import Affine\n",
    "from rasterio.plot import reshape_as_raster\n",
    "from rasterio.merge import merge\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "\n",
    "from shapely import wkt\n",
    "from shapely.geometry import Polygon, box\n",
    "from shapely.ops import transform\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from sentinel2download.downloader import Sentinel2Downloader\n",
    "from sentinel2download.overlap import Sentinel2Overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Transform AOI and get bound_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi = gp.GeoDataFrame(geometry=[wkt.loads(AOI)], crs=\"epsg:4326\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ð¡reate base path, usually env=jovyan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = f\"/home/{os.getenv('NB_USER')}/work\"\n",
    "BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentinel_grid = gp.read_file(\"sentinel2grid.geojson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Overlap AOI with sentinel2grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsg_code(longitude, latitude):\n",
    "        \"\"\"\n",
    "        Generates EPSG code from lon, lat\n",
    "        :param longitude: float\n",
    "        :param latitude: float\n",
    "        :return: int, EPSG code\n",
    "        \"\"\"\n",
    "\n",
    "        def _zone_number(lat, lon):\n",
    "            if 56 <= lat < 64 and 3 <= lon < 12:\n",
    "                return 32\n",
    "            if 72 <= lat <= 84 and lon >= 0:\n",
    "                if lon < 9:\n",
    "                    return 31\n",
    "                elif lon < 21:\n",
    "                    return 33\n",
    "                elif lon < 33:\n",
    "                    return 35\n",
    "                elif lon < 42:\n",
    "                    return 37\n",
    "\n",
    "            return int((lon + 180) / 6) + 1\n",
    "\n",
    "        zone = _zone_number(latitude, longitude)\n",
    "\n",
    "        if latitude > 0:\n",
    "            return 32600 + zone\n",
    "        else:\n",
    "            return 32700 + zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _intersect(aoi, grid):\n",
    "    # Get the indices of the tiles that are likely to be inside the bounding box of the given Polygon\n",
    "    geometry = aoi.geometry[0]\n",
    "\n",
    "    tiles_indexes = list(grid.sindex.intersection(geometry.bounds))\n",
    "    grid = grid.loc[tiles_indexes]\n",
    "\n",
    "    # Make the precise tiles in Polygon query\n",
    "    grid = grid.loc[grid.intersects(geometry)]\n",
    "\n",
    "    # intersection area\n",
    "    epsg = epsg_code(geometry.centroid.x, geometry.centroid.y)\n",
    "\n",
    "    # to UTM projection in meters\n",
    "    aoi.to_crs(epsg=epsg, inplace=True)\n",
    "    grid.to_crs(epsg=epsg, inplace=True)\n",
    "\n",
    "    return grid, epsg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intersected_tiles(aoi, grid):\n",
    "    \n",
    "    grid, epsg = _intersect(aoi, sentinel_grid)\n",
    "    \n",
    "    \n",
    "    grid.set_index(\"Name\", drop=False, inplace=True)    \n",
    "    intersected_grid = {\"tile\": [], \"geometry\": []}\n",
    "\n",
    "    rest_aoi = aoi.copy()\n",
    "    while rest_aoi.area.sum() > 0:\n",
    "        intersection = gp.overlay(rest_aoi, grid, how=\"intersection\")\n",
    "        argmax = intersection.area.argmax()\n",
    "\n",
    "        tile = intersection.loc[argmax, \"Name\"]\n",
    "        intersected_geometry = intersection.loc[argmax, \"geometry\"]\n",
    "        \n",
    "        intersected_grid[\"tile\"].append(tile)\n",
    "        intersected_grid[\"geometry\"].append(intersected_geometry)\n",
    "        \n",
    "        biggest_intersection = grid.loc[[tile]]\n",
    "        rest_aoi = gp.overlay(rest_aoi, biggest_intersection, how=\"difference\")\n",
    "        grid = grid.loc[intersection[\"Name\"]]\n",
    "    \n",
    "    overlap_tiles = gp.GeoDataFrame(intersected_grid, crs=epsg)\n",
    "    overlap_tiles.to_crs(epsg=4326, inplace=True)\n",
    "\n",
    "    return overlap_tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_tiles = get_intersected_tiles(aoi.copy(), sentinel_grid.copy())\n",
    "overlap_tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_tiles.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = os.path.join(BASE, \".secret/sentinel2_google_api_key.json\")\n",
    "LOAD_DIR = os.path.join(BASE, \"satellite_imagery\")\n",
    "\n",
    "PRODUCT_TYPE = 'L2A'\n",
    "BANDS = {'TCI', 'B04', 'B08', }\n",
    "CONSTRAINTS = {'NODATA_PIXEL_PERCENTAGE': 10.0, 'CLOUDY_PIXEL_PERCENTAGE': 5.0, }\n",
    "\n",
    "LAYERS = ['TCI', 'NDVI', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "END_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_date(date, delta=5, format='%Y-%m-%d'):\n",
    "    date = datetime.strptime(date, format)\n",
    "    date = date - timedelta(days=delta)    \n",
    "    return datetime.strftime(date, format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Define max shift in dates - 30 days for loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SHIFT = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SHIFT_ITERS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(tiles, start_date, end_date):\n",
    "    loader = Sentinel2Downloader(API_KEY)\n",
    "    \n",
    "    loadings = dict()\n",
    "        \n",
    "    for tile in tiles:\n",
    "        start = start_date\n",
    "        end = end_date\n",
    "        \n",
    "        print(f\"Loading images for tile: {tile}...\")\n",
    "        count = 0\n",
    "        while count < MAX_SHIFT_ITERS:\n",
    "            loaded = loader.download(PRODUCT_TYPE,\n",
    "                                [tile],\n",
    "                                start_date=start,\n",
    "                                end_date=end,\n",
    "                                output_dir=LOAD_DIR,                       \n",
    "                                bands=BANDS,\n",
    "                                constraints=CONSTRAINTS)\n",
    "        \n",
    "            if not loaded:\n",
    "                end = start_date\n",
    "                start = shift_date(start_date, delta=MAX_SHIFT) \n",
    "                print(f\"For tile: {tile} and dates {start_date} {end_date} proper images not found! Shift dates to {start} {end}!\")\n",
    "            else:\n",
    "                break\n",
    "            count += 1\n",
    "        if loaded:\n",
    "            loadings[tile] = loaded\n",
    "            print(f\"Loading images for tile {tile} finished\")\n",
    "        else:\n",
    "            print(f\"Images for tile {tile} were not loaded!\")\n",
    "        \n",
    "    # tile_folders = dict()\n",
    "    # for tile, tile_paths in loadings.items():\n",
    "    #    tile_folders[tile] = {str(Path(tile_path[0]).parent) for tile_path in tile_paths}\n",
    "    return loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings = load_images(overlap_tiles.tile.values, START_DATE, END_DATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Filter loadings for every tile, get last image in daterange and bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_date(loadings):\n",
    "    def _find_last_date(folders):        \n",
    "        dates = list()\n",
    "        for folder in folders:        \n",
    "            search = re.search(r\"_(\\d+)T\\d+_\", str(folder))\n",
    "            date = search.group(1)\n",
    "            date = datetime.strptime(date, '%Y%m%d')\n",
    "            dates.append(date)    \n",
    "        last_date = max(dates)\n",
    "        last_date = datetime.strftime(last_date, '%Y%m%d')\n",
    "        return last_date\n",
    "    \n",
    "    filtered = dict()\n",
    "    for tile, items in loadings.items():\n",
    "        try:\n",
    "            last_date = _find_last_date(items)\n",
    "            bands_paths = dict()\n",
    "            for path, _ in items:\n",
    "                if last_date in path:\n",
    "                    if 'B04_10m.jp2' in path:\n",
    "                        bands_paths['RED'] = path\n",
    "                    if 'B08_10m.jp2' in path:\n",
    "                        bands_paths['NIR'] = path\n",
    "                    if 'TCI_10m.jp2' in path:\n",
    "                        bands_paths['TCI'] = path\n",
    "            filtered[tile] = dict(paths=bands_paths, date=last_date)\n",
    "        except Exception as ex:\n",
    "            print(f\"Error for {tile}: {str(ex)}\")\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = filter_by_date(loadings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Calculate NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = os.path.join(BASE, \"results/example/tci_ndvi\")\n",
    "\n",
    "NOTEBOOK_DIR = os.path.join(BASE, \"notebooks/example/tci_ndvi\")\n",
    "COLORMAP_BRBG = os.path.join(NOTEBOOK_DIR, \"brbg.npy\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Prepare color coding for NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_colors(colors):\n",
    "    colors = np.load(COLORMAP_BRBG)\n",
    "    # delete last channel, we use rgb\n",
    "    colors = np.delete(colors, 3, axis=1)\n",
    "    # colormap colors values in range [0-255], but in our case 0 - no data, -> have to color as [0, 0, 0] \n",
    "    colors[colors == 0] = 1\n",
    "    colors[0] = [0, 0, 0]\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = prepare_colors(COLORMAP_BRBG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(ndvi, a=1, b=255, nodata=0.0):\n",
    "    # ndvi is in range [-1; 1], nodata is setted to 0.0 value. Be careful with comprassions!\n",
    "    min = -1 # np.nanmin(ndvi)\n",
    "    max = 1 # np.nanmax(ndvi)\n",
    "    scaled = (b - a) * (ndvi - min) / (max - min) + a\n",
    "    scaled = np.around(scaled)\n",
    "    scaled[np.isnan(scaled) == True] = nodata\n",
    "    scaled = scaled.astype(np.uint8)\n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_ndvi(scaled, colors):\n",
    "    colored = np.reshape(colors[scaled.flatten()], tuple((*scaled.shape, 3)))\n",
    "    colored = reshape_as_raster(colored)\n",
    "    return colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NDVI(nir_path, red_path, save_path):\n",
    "    # Asllow division by zero\n",
    "    np.seterr(divide='ignore', invalid='ignore')\n",
    "    \n",
    "    with rasterio.open(nir_path) as src:\n",
    "        nir = src.read(1).astype(rasterio.float32)\n",
    "        crs = str(src.crs)\n",
    "    with rasterio.open(red_path) as src:\n",
    "        red = src.read(1).astype(rasterio.float32)\n",
    "\n",
    "    # Calculate NDVI\n",
    "    ndvi = ((nir - red) / (nir + red)) \n",
    "    \n",
    "    scaled = scale(ndvi)\n",
    "    colored = color_ndvi(scaled, COLORS) \n",
    "    \n",
    "    \n",
    "    # Set spatial characteristics of the output object\n",
    "    out_meta = src.meta.copy()    \n",
    "    out_meta.update(dtype=rasterio.uint8,\n",
    "                    driver='GTiff',\n",
    "                    nodata=0,\n",
    "                    count=3, )\n",
    "\n",
    "    # Create the file\n",
    "    with rasterio.open(save_path, 'w', **out_meta) as dst:\n",
    "         dst.write(colored)\n",
    "    return crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_crs(poly, target, current='EPSG:4326'):\n",
    "    # print(f\"TARGET CRS: {target}\")\n",
    "    project = pyproj.Transformer.from_crs(pyproj.CRS(current), pyproj.CRS(target), always_xy=True).transform\n",
    "    transformed_poly = transform(project, poly)\n",
    "    return transformed_poly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(input_path, output_path, polygon, date, request_id, name=None):\n",
    "    with rasterio.open(input_path) as src:\n",
    "        out_image, out_transform = rasterio.mask.mask(src, [polygon], crop=True)\n",
    "        # print(out_transform)\n",
    "        out_meta = src.meta\n",
    "        \n",
    "        out_meta.update(driver='GTiff',\n",
    "                        height=out_image.shape[1],\n",
    "                        width=out_image.shape[2],\n",
    "                        transform=out_transform,\n",
    "                        nodata=0, )\n",
    "\n",
    "    with rasterio.open(output_path, \"w\", **out_meta) as dest:\n",
    "        dest.update_tags(start_date=date, end_date=date, request_id=request_id)\n",
    "        if name:\n",
    "            dest.update_tags(name=name)\n",
    "        dest.write(out_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Calculate and crop NDVI, TCI\n",
    "\n",
    "#### Filenames have next names: REQUESTID_TILE_ID_ACQUIREDDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = os.path.join(RESULTS_DIR, str(REQUEST_ID))\n",
    "RESULTS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not filtered:\n",
    "    raise ValueError(\"Images not loaded for given AOI. Change dates, constraints\")\n",
    "    \n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "for row in overlap_tiles.itertuples():\n",
    "    tile = row.tile\n",
    "    polygon = row.geometry\n",
    "    \n",
    "    try:\n",
    "        paths = filtered[tile]['paths']\n",
    "        print(f\"{tile}: Start calculation TCI, NDVI\")\n",
    "        \n",
    "        acquired_date = filtered[tile]['date']\n",
    "        base_filename = f\"{REQUEST_ID}_{tile}_{acquired_date}_\"\n",
    "        temp_ndvi_filename = os.path.join(RESULTS_DIR, base_filename + \"NDVI.tif.temp\")\n",
    "        temp_tci_filename = os.path.join(RESULTS_DIR, base_filename + \"TCI.tif.temp\")\n",
    "        \n",
    "        tile_crs = NDVI(paths['NIR'], paths['RED'], temp_ndvi_filename)\n",
    "        transformed_poly = to_crs(polygon, tile_crs)\n",
    "        \n",
    "        # Crop and save NDVI\n",
    "        crop(temp_ndvi_filename, temp_ndvi_filename, transformed_poly, acquired_date, REQUEST_ID)\n",
    "        # Crop and save TCI\n",
    "        crop(paths['TCI'], temp_tci_filename, transformed_poly, acquired_date, REQUEST_ID)\n",
    "        \n",
    "        print(f\"{tile}: End calculation TCI, NDVI\")\n",
    "    \n",
    "        ndvi_filename = temp_ndvi_filename[:-5]\n",
    "        tci_filename = temp_tci_filename[:-5]\n",
    "        print(f\"{tile}: Rename {temp_ndvi_filename}->{ndvi_filename}\\n {temp_tci_filename}->{tci_filename}\")\n",
    "        os.rename(temp_ndvi_filename, ndvi_filename)\n",
    "        os.rename(temp_tci_filename, tci_filename)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"{tile}: Cannot calculate TCI, NDVI: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
