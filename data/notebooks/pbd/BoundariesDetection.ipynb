{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting boundaries for given AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import rasterio.mask\n",
    "import tempfile\n",
    "import shapely\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "from os.path import join, basename, split\n",
    "from skimage import measure\n",
    "from scipy.ndimage import rotate\n",
    "from rasterio.features import rasterize, shapes\n",
    "from shapely.geometry import Polygon, shape\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "from sentinel2download.downloader import Sentinel2Downloader\n",
    "from preprocessing import preprocess_sentinel_raw_data, read_raster\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tiles(aoi_path, sentinel_tiles_path):\n",
    "    '''\n",
    "    Returns Sentinel-2 tiles that intersects with specified AoI.\n",
    "\n",
    "        Parameters:\n",
    "            aoi_path (str): Path to geojson/shp file with AoI to process.\n",
    "            sentinel_tiles_path (str): Path to geojson/shp file with all Sentinel-2 tiles.\n",
    "\n",
    "        Returns:\n",
    "            date_tile_info (GeoDataFrame): Filtered tiles (tileID, geometry, date).\n",
    "    '''\n",
    "    aoi_file = gpd.read_file(aoi_path)\n",
    "    sentinel_tiles = gpd.read_file(sentinel_tiles_path)\n",
    "    sentinel_tiles.set_index(\"Name\", drop=False, inplace=True)\n",
    "\n",
    "    best_interseciton = {\"tileID\": [], \"geometry\": []}\n",
    "    rest_aoi = aoi_file.copy()\n",
    "\n",
    "    while rest_aoi.area.sum() > 0:\n",
    "        res_intersection = gpd.overlay(rest_aoi, sentinel_tiles, how=\"intersection\")\n",
    "        biggest_area_idx = res_intersection.area.argmax()\n",
    "\n",
    "        tileID = res_intersection.loc[biggest_area_idx, \"Name\"]\n",
    "        this_aoi = res_intersection.loc[biggest_area_idx, \"geometry\"]\n",
    "\n",
    "        best_interseciton[\"tileID\"].append(tileID)\n",
    "        best_interseciton[\"geometry\"].append(this_aoi)\n",
    "\n",
    "        biggest_intersection = sentinel_tiles.loc[[tileID]]\n",
    "        rest_aoi = gpd.overlay(rest_aoi, biggest_intersection, how=\"difference\")\n",
    "        sentinel_tiles = sentinel_tiles.loc[res_intersection[\"Name\"]]\n",
    "\n",
    "    date_tile_info = gpd.GeoDataFrame(best_interseciton)\n",
    "    date_tile_info.crs = aoi_file.crs\n",
    "    \n",
    "    return date_tile_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_segmentation_mask_with_multiple_th(image_path, thresholds, min_edge_size, min_obj_size, th_size=(11, 3)):\n",
    "    '''\n",
    "    Run segmentation on the given raster to find edges. \n",
    "    Combine multiple predictions with different thresholds with cv2.adaptiveThreshold.\n",
    "\n",
    "        Parameters:\n",
    "            image_path (str): Path to raster which will be processed.\n",
    "            thresholds (:obj:`list` of :obj:`float`): List of thresholds used to filter weak edges.\n",
    "            min_edge_size (int): Edges with lower size will be filtered.\n",
    "            min_obj_size (int): Instances with lower size will be filtered.\n",
    "            th_size (:obj:`tuple` of :obj:`int`): Size of cv2.adaptiveThreshold filter.\n",
    "\n",
    "        Returns:\n",
    "            img (numpy.array): Binary image with segmented instances.\n",
    "            meta (dict): Source raster metadata\n",
    "    '''\n",
    "    bands, meta = read_raster(image_path)\n",
    "    results = [None] * len(thresholds)\n",
    "    for i, th in enumerate(thresholds):\n",
    "        results[i], _ = find_segmentation_mask(image_path, th, min_edge_size, min_obj_size)\n",
    "    combined = np.mean(results, 0).astype(np.uint8)\n",
    "    thresholded = cv2.adaptiveThreshold(\n",
    "        combined,\n",
    "        255,\n",
    "        cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "        cv2.THRESH_BINARY,\n",
    "        *th_size\n",
    "    )\n",
    "    labeled = label_detected_instances(thresholded, connectivity=1)\n",
    "    labeled = remove_small_objects(labeled, min_obj_size / 10)\n",
    "    labeled = remove_background(labeled, bands)\n",
    "    labeled[thresholded == 0] = 0\n",
    "    img = convert_to_binary(labeled)\n",
    "    \n",
    "    return img, meta\n",
    "\n",
    "\n",
    "def find_segmentation_mask(image_path, edge_combination_th, min_edge_size, min_obj_size):\n",
    "    '''\n",
    "    Run segmentation on the given raster to find edges.\n",
    "\n",
    "        Parameters:\n",
    "            image_path (str): Path to raster which will be processed.\n",
    "            edge_combination_th (float): Threshold that used to filter weak edges.\n",
    "            min_edge_size (int): Edges with lower size will be filtered.\n",
    "            min_obj_size (int): Instances with lower size will be filtered.\n",
    "\n",
    "        Returns:\n",
    "            binary_img (numpy.array): Binary image with segmented instances.\n",
    "            meta (dict): Source raster metadata\n",
    "    '''\n",
    "    bands, meta = read_raster(image_path)\n",
    "    avg_std = compute_image_standard_deviation(bands)\n",
    "    filter_list = create_edging_filters()\n",
    "    edges = apply_edging_filters(avg_std, filter_list)\n",
    "    edge_direction_list = combine_edges_layers(avg_std, edges, edge_combination_th)\n",
    "    edge_direction_list = remove_short_edges(edge_direction_list, min_edge_size)\n",
    "    binary_mask = edges_union(edge_direction_list)\n",
    "    labeled_image = label_detected_instances(binary_mask)\n",
    "    labeled_image = remove_small_objects(labeled_image, min_obj_size)\n",
    "    labeled_image = remove_background(labeled_image, bands)\n",
    "    binary_img = convert_to_binary(labeled_image)\n",
    "\n",
    "    return binary_img, meta\n",
    "\n",
    "\n",
    "def compute_image_standard_deviation(bands, kernel_size=(5, 5)):\n",
    "    std_list = [\n",
    "        find_edges_with_standard_deviation(b, kernel_size) for b in bands\n",
    "    ]\n",
    "    return np.mean(std_list, 0)\n",
    "\n",
    "\n",
    "def find_edges_with_standard_deviation(sample, filter_size=(3, 3)):\n",
    "    mean = cv2.blur(sample, filter_size)\n",
    "    mean_sqr = cv2.blur(sample * sample, filter_size)\n",
    "    std = cv2.sqrt(mean_sqr - mean*mean)\n",
    "    return std\n",
    "\n",
    "\n",
    "def create_edging_filters(length=13, count=16):\n",
    "    base_filter = np.array([\n",
    "        [-1] * length,\n",
    "        [1] * length,\n",
    "        [0] * length,\n",
    "    ])\n",
    "    filter_list = [None] * count * 2\n",
    "    filter_list[0] = base_filter\n",
    "    step = 180 / count\n",
    "\n",
    "    for i in range(count // 2):\n",
    "        filter_ = rotate(base_filter, i * step, order=0)\n",
    "        filter_list[i*4] = filter_\n",
    "        for j in range(1, 4):\n",
    "            filter_list[i*4+j] = np.rot90(filter_, j)\n",
    "\n",
    "    return filter_list\n",
    "\n",
    "\n",
    "def apply_edging_filters(sample, filter_list):\n",
    "    return [cv2.filter2D(sample, -1, f) for f in filter_list]\n",
    "\n",
    "\n",
    "def combine_edges_layers(avg_std, edges, th):\n",
    "    filter_count = len(edges) // 2\n",
    "    local_max_left = [None] * filter_count\n",
    "    local_max_right = [None] * filter_count\n",
    "\n",
    "    for i in range(filter_count // 2):\n",
    "        local_max_left[2*i] = cv2.bitwise_and(avg_std, edges[4*i])\n",
    "        local_max_left[2*i+1] = cv2.bitwise_and(avg_std, edges[4*i+1])\n",
    "        local_max_right[2*i] = cv2.bitwise_and(avg_std, edges[4*i+2])\n",
    "        local_max_right[2*i+1] = cv2.bitwise_and(avg_std, edges[4*i+3])\n",
    "\n",
    "    local_max_left = np.asanyarray(local_max_left)\n",
    "    local_max_right = np.asanyarray(local_max_right)\n",
    "\n",
    "    combined_result = np.zeros_like(local_max_left, np.uint8)\n",
    "    combined_result[\n",
    "        (local_max_left > 0) &\n",
    "        (local_max_right > 0) &\n",
    "        (local_max_left + local_max_right > th)\n",
    "    ] = 1\n",
    "\n",
    "    return combined_result\n",
    "\n",
    "\n",
    "def remove_short_edges(edge_direction_list, min_edge_size):\n",
    "    res = [None] * len(edge_direction_list)\n",
    "    for i, edge_direction in enumerate(edge_direction_list):\n",
    "        labeled_image = label_detected_instances(edge_direction, 0, 2)\n",
    "        labels, counts_labels = np.unique(labeled_image, return_counts=True)\n",
    "        edge_direction = np.isin(\n",
    "            labeled_image,\n",
    "            labels[counts_labels > min_edge_size]\n",
    "        ) & (edge_direction > 0)\n",
    "\n",
    "        res[i] = edge_direction.astype(np.uint8)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def edges_union(edges):\n",
    "    result = edges[0]\n",
    "    for e in edges[1:]:\n",
    "        result = cv2.bitwise_or(result, e)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def label_detected_instances(binary_mask, background=1, connectivity=2):\n",
    "    return measure.label(\n",
    "        binary_mask,\n",
    "        background=background,\n",
    "        connectivity=connectivity\n",
    "    )\n",
    "\n",
    "\n",
    "def remove_small_objects(labeled_image, min_obj_size):\n",
    "    labels, counts_labels = np.unique(labeled_image, return_counts=True)\n",
    "    labeled_image[np.isin(\n",
    "        labeled_image,\n",
    "        labels[counts_labels < min_obj_size]\n",
    "    )] = 0\n",
    "    return labeled_image\n",
    "\n",
    "\n",
    "def remove_background(prediction, bands):\n",
    "    mask = np.sum(bands, axis=0) == 0\n",
    "    prediction[mask] = 0\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def convert_to_binary(img):\n",
    "    img[img > 0] = 255\n",
    "    return img.astype(np.uint8)\n",
    "\n",
    "\n",
    "def polygonize(binary_img, meta, transform=True):\n",
    "    polygons = shapes(\n",
    "        binary_img, \n",
    "        binary_img, \n",
    "        transform=meta[\"transform\"],\n",
    "        connectivity=8\n",
    "    )\n",
    "    return [shape(poly) for poly, _ in polygons]\n",
    "\n",
    "\n",
    "def process_polygons(result_df, current_crs, limit=500, dst_crs=\"EPSG:4326\"):\n",
    "    \"\"\"\n",
    "    Prepare result Dataframe with polygons\n",
    "\n",
    "        Parameters:\n",
    "            result_df (pd.DataFrame): Result DataFrame\n",
    "            limit (int): min area for polygon in m2\n",
    "        Returns:\n",
    "            GeoDataFrame: GeoDataFrame ready for saving\n",
    "    \"\"\"\n",
    "        \n",
    "    gdf = gpd.GeoDataFrame(result_df)\n",
    "    gdf.crs = current_crs\n",
    "    \n",
    "    # fix invalid polygons\n",
    "    # gdf[\"geometry\"] = gdf.apply(lambda row: row.geometry.buffer(0), axis=1)\n",
    "    # select only valid polygons\n",
    "    # gdf = gdf.loc[gdf.is_valid]\n",
    "\n",
    "    # print(gdf.crs)\n",
    "    # TODO: can be uncomment if needed\n",
    "    # gdf = gdf.loc[gdf.area >= limit]\n",
    "    \n",
    "    gdf.to_crs(dst_crs, inplace=True)\n",
    "    # expand each polygon\n",
    "    # gdf.geometry = gdf.geometry.buffer(0.0001, 1)\n",
    "    return gdf\n",
    "\n",
    "\n",
    "def save_polygons(gdf, save_path):\n",
    "    if len(gdf) == 0:\n",
    "        print('No polygons detected.')\n",
    "        return\n",
    "\n",
    "    directory = os.path.dirname(save_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "    save_path = save_path + \".temp\" \n",
    "    gdf.to_file(save_path, driver='GeoJSON')\n",
    "    os.rename(save_path, save_path[:-5])\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find tile indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = f\"/home/{os.getenv('NB_USER')}/work\"\n",
    "\n",
    "API_KEY = os.path.join(BASE, \".secret/sentinel2_google_api_key.json\")\n",
    "LOAD_DIR = os.path.join(BASE, \"satellite_imagery\")\n",
    "RESULTS_DIR = os.path.join(BASE, \"results/pbd\")\n",
    "\n",
    "PBD_DIR = os.path.join(BASE, \"notebooks/pbd\")\n",
    "\n",
    "BANDS = {'TCI', 'B08', }\n",
    "\n",
    "CONSTRAINTS = {'NODATA_PIXEL_PERCENTAGE': 15.0, 'CLOUDY_PIXEL_PERCENTAGE': 40.0, }\n",
    "# CONSTRAINTS = {'NODATA_PIXEL_PERCENTAGE': 10.0, 'CLOUDY_PIXEL_PERCENTAGE': 5.0, }\n",
    "\n",
    "PRODUCT_TYPE = 'L1C'\n",
    "\n",
    "START_DATE = \"2017-09-12\"\n",
    "END_DATE = \"2017-09-12\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/work/notebooks/pbd/data/20170912_075604_1032_aoi.geojson'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aoi_path = os.getenv(\"AOI\", os.path.join(BASE, \"notebooks/pbd/data/20170912_075604_1032_aoi.geojson\"))     \n",
    "aoi_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentinel_tiles_path = \"sentinel2grid.geojson\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find overlap tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tileID</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36UXA</td>\n",
       "      <td>POLYGON Z ((35.11965 49.98928 0.00000, 35.1208...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tileID                                           geometry\n",
       "0  36UXA  POLYGON Z ((35.11965 49.98928 0.00000, 35.1208..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_tile_info = get_tiles(aoi_path, sentinel_tiles_path)\n",
    "date_tile_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_folder(tile_folder, file, limit, nodata):\n",
    "    with rasterio.open(os.path.join(tile_folder, file)) as src:              \n",
    "        # Read in image as a numpy array\n",
    "        array = src.read(1)\n",
    "        # Count the occurance of NoData values in np array\n",
    "        nodata_count = np.count_nonzero(array == nodata)\n",
    "        # Get a % of NoData pixels\n",
    "        nodata_percentage = round(nodata_count / array.size * 100, 2)\n",
    "        print(f\"NODATA_PIXEL_PERCENTAGE for {tile_folder} images: {nodata_percentage}%\")\n",
    "        if nodata_percentage <= limit:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_nodata(loadings, product_type, limit=15.0, nodata=0):\n",
    "    filtered = dict()\n",
    "    \n",
    "    print(f\"Checking NODATA_PIXEL_PERCENTAGE for {product_type}\") \n",
    "\n",
    "    for tile, tile_paths in loadings.items():\n",
    "        try:\n",
    "            for tile_path in tile_paths:\n",
    "                tile_folder = Path(tile_path[0]).parent\n",
    "                print(tile_folder)\n",
    "                if product_type == 'L1C' and limit:\n",
    "                     if _check_folder(tile_folder, limit, nodata):\n",
    "                        filtered[tile] = tile_folder\n",
    "                else:\n",
    "                    filtered[tile] = tile_folder\n",
    "        except Exception as ex:\n",
    "            print(f\"Error for {tile}: {str(ex)}\")\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(api_key, tiles, start_date, end_date, output_dir, product_type=\"L2A\"):\n",
    "    loader = Sentinel2Downloader(api_key)\n",
    "    loadings = dict()\n",
    "    for tile in tiles:\n",
    "        print(f\"Loading images for tile: {tile}...\")\n",
    "        loaded = loader.download(product_type,\n",
    "                                 [tile],\n",
    "                                 start_date=start_date,\n",
    "                                 end_date=end_date,\n",
    "                                 output_dir=output_dir,                       \n",
    "                                 bands=BANDS,\n",
    "                                constraints=CONSTRAINTS)\n",
    "        \n",
    "        print(f\"Loading images for tile {tile} finished\")\n",
    "        loadings[tile] = loaded\n",
    "    \n",
    "    tile_folders = dict()\n",
    "    for tile, tile_paths in loadings.items():\n",
    "        tile_folders[tile] = {str(Path(tile_path[0]).parent) for tile_path in tile_paths}\n",
    "    return tile_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images for tile: 36UXA...\n",
      "Loading images for tile 36UXA finished\n"
     ]
    }
   ],
   "source": [
    "loadings = load_images(API_KEY, date_tile_info.tileID.values, START_DATE, END_DATE, LOAD_DIR, PRODUCT_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'36UXA': {'/home/jovyan/work/satellite_imagery/S2B_MSIL1C_20170912T084549_N0205_R107_T36UXA_20170912T085508'}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### if product type == L1C, check images NODATA_PIXEL_PERCENTAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_nodata(loadings, product_type, limit=15.0, nodata=0):\n",
    "    filtered = dict()\n",
    "    \n",
    "    print(f\"Checking NODATA_PIXEL_PERCENTAGE for {product_type}\")            \n",
    "    \n",
    "    for tile, folders in loadings.items():\n",
    "        filtered_folders = set()\n",
    "        for folder in folders:\n",
    "            # print(folder)\n",
    "            for file in os.listdir(folder):\n",
    "                if file.endswith(\".jp2\") and \"OPER\" not in file:\n",
    "                    if product_type == 'L1C' and limit:\n",
    "                         if _check_folder(folder, file, limit, nodata):\n",
    "                            filtered_folders.add(folder)\n",
    "                            break\n",
    "                    else:\n",
    "                        filtered_folders.add(folder)\n",
    "        filtered[tile] = filtered_folders\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking NODATA_PIXEL_PERCENTAGE for L1C\n",
      "NODATA_PIXEL_PERCENTAGE for /home/jovyan/work/satellite_imagery/S2B_MSIL1C_20170912T084549_N0205_R107_T36UXA_20170912T085508 images: 5.45%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'36UXA': {'/home/jovyan/work/satellite_imagery/S2B_MSIL1C_20170912T084549_N0205_R107_T36UXA_20170912T085508'}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checked = check_nodata(loadings, PRODUCT_TYPE)\n",
    "checked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### select last folder with last date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_date(loadings):\n",
    "    def _find_last_date(folders):        \n",
    "        dates = list()\n",
    "        for folder in folders:        \n",
    "            search = re.search(r\"_(\\d+)T\\d+_\", str(folder))\n",
    "            date = search.group(1)\n",
    "            date = datetime.strptime(date, '%Y%m%d')\n",
    "            dates.append(date)    \n",
    "        last_date = max(dates)\n",
    "        last_date = datetime.strftime(last_date, '%Y%m%d')\n",
    "        return last_date\n",
    "    \n",
    "    filtered = dict()\n",
    "    for tile, folders in loadings.items():\n",
    "        last_date = _find_last_date(folders)\n",
    "        for folder in folders:\n",
    "            if last_date in folder:\n",
    "                filtered[tile] = folder\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'36UXA': '/home/jovyan/work/satellite_imagery/S2B_MSIL1C_20170912T084549_N0205_R107_T36UXA_20170912T085508'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered = filter_date(checked)\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not filtered:\n",
    "    raise ValueError(\"Images not loaded. Change date or constraints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = [5.0, 6.0, 7.0, 8.0, 9.0]\n",
    "min_edge_size = 200\n",
    "min_obj_size = 2000\n",
    "\n",
    "origin_name = os.path.basename(aoi_path).replace(\".geojson\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/satellite_imagery/S2B_MSIL1C_20170912T084549_N0205_R107_T36UXA_20170912T085508\n",
      "Processing 36UXA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:43<00:00, 43.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing 36UXA\n",
      "/home/jovyan/work/notebooks/pbd/20170912_075604_1032_aoi_prediction_vy1.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>id</th>\n",
       "      <th>tileID</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POLYGON ((35.22546 50.01661, 35.22545 50.01652...</td>\n",
       "      <td>20170912_075604_1032_aoi_0</td>\n",
       "      <td>36UXA</td>\n",
       "      <td>2017-09-12</td>\n",
       "      <td>2017-09-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POLYGON ((35.23219 50.01432, 35.23216 50.01378...</td>\n",
       "      <td>20170912_075604_1032_aoi_1</td>\n",
       "      <td>36UXA</td>\n",
       "      <td>2017-09-12</td>\n",
       "      <td>2017-09-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POLYGON ((35.17476 50.01307, 35.17476 50.01298...</td>\n",
       "      <td>20170912_075604_1032_aoi_2</td>\n",
       "      <td>36UXA</td>\n",
       "      <td>2017-09-12</td>\n",
       "      <td>2017-09-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POLYGON ((35.20050 50.01115, 35.20049 50.01106...</td>\n",
       "      <td>20170912_075604_1032_aoi_3</td>\n",
       "      <td>36UXA</td>\n",
       "      <td>2017-09-12</td>\n",
       "      <td>2017-09-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POLYGON ((35.24603 50.00883, 35.24603 50.00874...</td>\n",
       "      <td>20170912_075604_1032_aoi_4</td>\n",
       "      <td>36UXA</td>\n",
       "      <td>2017-09-12</td>\n",
       "      <td>2017-09-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>POLYGON ((35.22109 49.98548, 35.22108 49.98539...</td>\n",
       "      <td>20170912_075604_1032_aoi_60</td>\n",
       "      <td>36UXA</td>\n",
       "      <td>2017-09-12</td>\n",
       "      <td>2017-09-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>POLYGON ((35.23761 49.98372, 35.23760 49.98363...</td>\n",
       "      <td>20170912_075604_1032_aoi_61</td>\n",
       "      <td>36UXA</td>\n",
       "      <td>2017-09-12</td>\n",
       "      <td>2017-09-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>POLYGON ((35.23303 49.97229, 35.23303 49.97211...</td>\n",
       "      <td>20170912_075604_1032_aoi_62</td>\n",
       "      <td>36UXA</td>\n",
       "      <td>2017-09-12</td>\n",
       "      <td>2017-09-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>POLYGON ((35.23709 49.96943, 35.23708 49.96934...</td>\n",
       "      <td>20170912_075604_1032_aoi_63</td>\n",
       "      <td>36UXA</td>\n",
       "      <td>2017-09-12</td>\n",
       "      <td>2017-09-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>POLYGON ((35.24966 49.97899, 35.24966 49.97890...</td>\n",
       "      <td>20170912_075604_1032_aoi_64</td>\n",
       "      <td>36UXA</td>\n",
       "      <td>2017-09-12</td>\n",
       "      <td>2017-09-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             geometry  \\\n",
       "0   POLYGON ((35.22546 50.01661, 35.22545 50.01652...   \n",
       "1   POLYGON ((35.23219 50.01432, 35.23216 50.01378...   \n",
       "2   POLYGON ((35.17476 50.01307, 35.17476 50.01298...   \n",
       "3   POLYGON ((35.20050 50.01115, 35.20049 50.01106...   \n",
       "4   POLYGON ((35.24603 50.00883, 35.24603 50.00874...   \n",
       "..                                                ...   \n",
       "60  POLYGON ((35.22109 49.98548, 35.22108 49.98539...   \n",
       "61  POLYGON ((35.23761 49.98372, 35.23760 49.98363...   \n",
       "62  POLYGON ((35.23303 49.97229, 35.23303 49.97211...   \n",
       "63  POLYGON ((35.23709 49.96943, 35.23708 49.96934...   \n",
       "64  POLYGON ((35.24966 49.97899, 35.24966 49.97890...   \n",
       "\n",
       "                             id tileID  start_date    end_date  \n",
       "0    20170912_075604_1032_aoi_0  36UXA  2017-09-12  2017-09-12  \n",
       "1    20170912_075604_1032_aoi_1  36UXA  2017-09-12  2017-09-12  \n",
       "2    20170912_075604_1032_aoi_2  36UXA  2017-09-12  2017-09-12  \n",
       "3    20170912_075604_1032_aoi_3  36UXA  2017-09-12  2017-09-12  \n",
       "4    20170912_075604_1032_aoi_4  36UXA  2017-09-12  2017-09-12  \n",
       "..                          ...    ...         ...         ...  \n",
       "60  20170912_075604_1032_aoi_60  36UXA  2017-09-12  2017-09-12  \n",
       "61  20170912_075604_1032_aoi_61  36UXA  2017-09-12  2017-09-12  \n",
       "62  20170912_075604_1032_aoi_62  36UXA  2017-09-12  2017-09-12  \n",
       "63  20170912_075604_1032_aoi_63  36UXA  2017-09-12  2017-09-12  \n",
       "64  20170912_075604_1032_aoi_64  36UXA  2017-09-12  2017-09-12  \n",
       "\n",
       "[65 rows x 5 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame([])\n",
    "\n",
    "with tempfile.TemporaryDirectory(dir=PBD_DIR) as tmpdirname:   \n",
    "    for i, tile in tqdm(date_tile_info.iterrows(), total=date_tile_info.shape[0]):\n",
    "        try:\n",
    "            tile_folder = Path(filtered[tile.tileID])\n",
    "            print(tile_folder)\n",
    "        except Exception as ex:\n",
    "            print(f\"Error for {tile.tileID}: {str(ex)}\")\n",
    "        else:\n",
    "            print(f\"Processing {tile.tileID}...\")\n",
    "    \n",
    "            raster_path = preprocess_sentinel_raw_data(\n",
    "                save_path=tmpdirname,\n",
    "                tile_folder=tile_folder,\n",
    "                aoi_mask=date_tile_info.loc[[i]]\n",
    "            )\n",
    "    \n",
    "            if len(th) == 1:\n",
    "                img, meta = find_segmentation_mask(\n",
    "                    raster_path, th[0],\n",
    "                    min_edge_size, min_obj_size\n",
    "                )\n",
    "            else:\n",
    "                img, meta = find_segmentation_mask_with_multiple_th(\n",
    "                    raster_path, th,\n",
    "                    min_edge_size, min_obj_size\n",
    "                )\n",
    "                df = pd.DataFrame({\"geometry\": polygonize(img, meta)})\n",
    "                df[\"id\"] = pd.Series(map(lambda x: f\"{origin_name}_{x}\", df.index.values))\n",
    "                df[\"tileID\"] = tile.tileID\n",
    "                df[\"start_date\"] = START_DATE\n",
    "                df[\"end_date\"] = END_DATE\n",
    "        \n",
    "\n",
    "            result_df = pd.concat([result_df, df])\n",
    "            \n",
    "            print(f\"Finished processing {tile.tileID}\")\n",
    "    # print(result_df)\n",
    "\n",
    "\n",
    "gdf = process_polygons(result_df, meta['crs'])\n",
    "save_path = os.path.join(RESULTS_DIR, f\"{origin_name}_prediction_vy1.geojson\")\n",
    "print(save_path)\n",
    "save_polygons(gdf, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}