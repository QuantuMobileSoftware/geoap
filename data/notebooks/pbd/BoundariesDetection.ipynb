{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting boundaries for given AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import rasterio.mask\n",
    "import tempfile\n",
    "\n",
    "from tqdm import tqdm\n",
    "from os.path import join, basename, split\n",
    "from skimage import measure\n",
    "from scipy.ndimage import rotate\n",
    "from rasterio.features import rasterize, shapes\n",
    "from shapely.geometry import Polygon, shape\n",
    "from pathlib import Path\n",
    "\n",
    "from sentinel2download.downloader import Sentinel2Downloader\n",
    "from preprocessing import preprocess_sentinel_raw_data, read_raster\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tiles(aoi_path, sentinel_tiles_path, date):\n",
    "    '''\n",
    "    Returns Sentinel-2 tiles that intersects with specified AoI.\n",
    "\n",
    "        Parameters:\n",
    "            aoi_path (str): Path to geojson/shp file with AoI to process.\n",
    "            sentinel_tiles_path (str): Path to geojson/shp file with all Sentinel-2 tiles.\n",
    "            date (str): Date in %Y%m%d format.\n",
    "\n",
    "        Returns:\n",
    "            date_tile_info (GeoDataFrame): Filtered tiles (tileID, geometry, date).\n",
    "    '''\n",
    "    aoi_file = gpd.read_file(aoi_path)\n",
    "    sentinel_tiles = gpd.read_file(sentinel_tiles_path)\n",
    "    sentinel_tiles.set_index(\"Name\", drop=False, inplace=True)\n",
    "\n",
    "    best_interseciton = {\"tileID\": [], \"geometry\": []}\n",
    "    rest_aoi = aoi_file.copy()\n",
    "\n",
    "    while rest_aoi.area.sum() > 0:\n",
    "        res_intersection = gpd.overlay(rest_aoi, sentinel_tiles, how=\"intersection\")\n",
    "        biggest_area_idx = res_intersection.area.argmax()\n",
    "\n",
    "        tileID = res_intersection.loc[biggest_area_idx, \"Name\"]\n",
    "        this_aoi = res_intersection.loc[biggest_area_idx, \"geometry\"]\n",
    "\n",
    "        best_interseciton[\"tileID\"].append(tileID)\n",
    "        best_interseciton[\"geometry\"].append(this_aoi)\n",
    "\n",
    "        biggest_intersection = sentinel_tiles.loc[[tileID]]\n",
    "        rest_aoi = gpd.overlay(rest_aoi, biggest_intersection, how=\"difference\")\n",
    "        sentinel_tiles = sentinel_tiles.loc[res_intersection[\"Name\"]]\n",
    "\n",
    "    date_tile_info = gpd.GeoDataFrame(best_interseciton)\n",
    "    date_tile_info[\"img_date\"] = date\n",
    "    date_tile_info.crs = aoi_file.crs\n",
    "    \n",
    "    return date_tile_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_segmentation_mask_with_multiple_th(image_path, thresholds, min_edge_size, min_obj_size, th_size=(11, 3)):\n",
    "    '''\n",
    "    Run segmentation on the given raster to find edges. \n",
    "    Combine multiple predictions with different thresholds with cv2.adaptiveThreshold.\n",
    "\n",
    "        Parameters:\n",
    "            image_path (str): Path to raster which will be processed.\n",
    "            thresholds (:obj:`list` of :obj:`float`): List of thresholds used to filter weak edges.\n",
    "            min_edge_size (int): Edges with lower size will be filtered.\n",
    "            min_obj_size (int): Instances with lower size will be filtered.\n",
    "            th_size (:obj:`tuple` of :obj:`int`): Size of cv2.adaptiveThreshold filter.\n",
    "\n",
    "        Returns:\n",
    "            img (numpy.array): Binary image with segmented instances.\n",
    "            meta (dict): Source raster metadata\n",
    "    '''\n",
    "    bands, meta = read_raster(image_path)\n",
    "    results = [None] * len(thresholds)\n",
    "    for i, th in enumerate(thresholds):\n",
    "        results[i], _ = find_segmentation_mask(image_path, th, min_edge_size, min_obj_size)\n",
    "    combined = np.mean(results, 0).astype(np.uint8)\n",
    "    thresholded = cv2.adaptiveThreshold(\n",
    "        combined,\n",
    "        255,\n",
    "        cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "        cv2.THRESH_BINARY,\n",
    "        *th_size\n",
    "    )\n",
    "    labeled = label_detected_instances(thresholded)\n",
    "    labeled = remove_background(labeled, bands)\n",
    "    labeled[thresholded == 0] = 0\n",
    "    img = convert_to_binary(labeled)\n",
    "\n",
    "    return img, meta\n",
    "\n",
    "\n",
    "def find_segmentation_mask(image_path, edge_combination_th, min_edge_size, min_obj_size):\n",
    "    '''\n",
    "    Run segmentation on the given raster to find edges.\n",
    "\n",
    "        Parameters:\n",
    "            image_path (str): Path to raster which will be processed.\n",
    "            edge_combination_th (float): Threshold that used to filter weak edges.\n",
    "            min_edge_size (int): Edges with lower size will be filtered.\n",
    "            min_obj_size (int): Instances with lower size will be filtered.\n",
    "\n",
    "        Returns:\n",
    "            binary_img (numpy.array): Binary image with segmented instances.\n",
    "            meta (dict): Source raster metadata\n",
    "    '''\n",
    "    bands, meta = read_raster(image_path)\n",
    "    avg_std = compute_image_standard_deviation(bands)\n",
    "    filter_list = create_edging_filters()\n",
    "    edges = apply_edging_filters(avg_std, filter_list)\n",
    "    edge_direction_list = combine_edges_layers(avg_std, edges, edge_combination_th)\n",
    "    edge_direction_list = remove_short_edges(edge_direction_list, min_edge_size)\n",
    "    binary_mask = edges_union(edge_direction_list)\n",
    "    labeled_image = label_detected_instances(binary_mask)\n",
    "    labeled_image = remove_small_objects(labeled_image, min_obj_size)\n",
    "    labeled_image = remove_background(labeled_image, bands)\n",
    "    binary_img = convert_to_binary(labeled_image)\n",
    "\n",
    "    return binary_img, meta\n",
    "\n",
    "\n",
    "def compute_image_standard_deviation(bands, kernel_size=(5, 5)):\n",
    "    std_list = [\n",
    "        find_edges_with_standard_deviation(b, kernel_size) for b in bands\n",
    "    ]\n",
    "    return np.mean(std_list, 0)\n",
    "\n",
    "\n",
    "def find_edges_with_standard_deviation(sample, filter_size=(3, 3)):\n",
    "    mean = cv2.blur(sample, filter_size)\n",
    "    mean_sqr = cv2.blur(sample * sample, filter_size)\n",
    "    std = cv2.sqrt(mean_sqr - mean*mean)\n",
    "    return std\n",
    "\n",
    "\n",
    "def create_edging_filters(length=13, count=16):\n",
    "    base_filter = np.array([\n",
    "        [-1] * length,\n",
    "        [1] * length,\n",
    "        [0] * length,\n",
    "    ])\n",
    "    filter_list = [None] * count * 2\n",
    "    filter_list[0] = base_filter\n",
    "    step = 180 / count\n",
    "\n",
    "    for i in range(count // 2):\n",
    "        filter_ = rotate(base_filter, i * step, order=0)\n",
    "        filter_list[i*4] = filter_\n",
    "        for j in range(1, 4):\n",
    "            filter_list[i*4+j] = np.rot90(filter_, j)\n",
    "\n",
    "    return filter_list\n",
    "\n",
    "\n",
    "def apply_edging_filters(sample, filter_list):\n",
    "    return [cv2.filter2D(sample, -1, f) for f in filter_list]\n",
    "\n",
    "\n",
    "def combine_edges_layers(avg_std, edges, th):\n",
    "    filter_count = len(edges) // 2\n",
    "    local_max_left = [None] * filter_count\n",
    "    local_max_right = [None] * filter_count\n",
    "\n",
    "    for i in range(filter_count // 2):\n",
    "        local_max_left[2*i] = cv2.bitwise_and(avg_std, edges[4*i])\n",
    "        local_max_left[2*i+1] = cv2.bitwise_and(avg_std, edges[4*i+1])\n",
    "        local_max_right[2*i] = cv2.bitwise_and(avg_std, edges[4*i+2])\n",
    "        local_max_right[2*i+1] = cv2.bitwise_and(avg_std, edges[4*i+3])\n",
    "\n",
    "    local_max_left = np.asanyarray(local_max_left)\n",
    "    local_max_right = np.asanyarray(local_max_right)\n",
    "\n",
    "    combined_result = np.zeros_like(local_max_left, np.uint8)\n",
    "    combined_result[\n",
    "        (local_max_left > 0) &\n",
    "        (local_max_right > 0) &\n",
    "        (local_max_left + local_max_right > th)\n",
    "    ] = 1\n",
    "\n",
    "    return combined_result\n",
    "\n",
    "\n",
    "def remove_short_edges(edge_direction_list, min_edge_size):\n",
    "    res = [None] * len(edge_direction_list)\n",
    "    for i, edge_direction in enumerate(edge_direction_list):\n",
    "        labeled_image = label_detected_instances(edge_direction, 0, 2)\n",
    "        labels, counts_labels = np.unique(labeled_image, return_counts=True)\n",
    "        edge_direction = np.isin(\n",
    "            labeled_image,\n",
    "            labels[counts_labels > min_edge_size]\n",
    "        ) & (edge_direction > 0)\n",
    "\n",
    "        res[i] = edge_direction.astype(np.uint8)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def edges_union(edges):\n",
    "    result = edges[0]\n",
    "    for e in edges[1:]:\n",
    "        result = cv2.bitwise_or(result, e)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def label_detected_instances(binary_mask, background=1, connectivity=2):\n",
    "    return measure.label(\n",
    "        binary_mask,\n",
    "        background=background,\n",
    "        connectivity=connectivity\n",
    "    )\n",
    "\n",
    "\n",
    "def remove_small_objects(labeled_image, min_obj_size):\n",
    "    labels, counts_labels = np.unique(labeled_image, return_counts=True)\n",
    "    labeled_image[np.isin(\n",
    "        labeled_image,\n",
    "        labels[counts_labels < min_obj_size]\n",
    "    )] = 0\n",
    "    return labeled_image\n",
    "\n",
    "\n",
    "def remove_background(prediction, bands):\n",
    "    mask = np.sum(bands, axis=0) == 0\n",
    "    prediction[mask] = 0\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def convert_to_binary(img):\n",
    "    img[img > 0] = 255\n",
    "    return img.astype(np.uint8)\n",
    "\n",
    "\n",
    "def polygonize(binary_img, meta, transform=True):\n",
    "    polygons = shapes(\n",
    "        binary_img, \n",
    "        binary_img, \n",
    "        transform=meta[\"transform\"],\n",
    "        connectivity=8\n",
    "    )\n",
    "    return [shape(poly) for poly, _ in polygons]\n",
    "\n",
    "\n",
    "def save_polygons(polygons, crs, save_path, dst_crs=\"EPSG:4326\"):\n",
    "    if len(polygons) == 0:\n",
    "        print('No polygons detected.')\n",
    "        return\n",
    "\n",
    "    directory = os.path.dirname(save_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    gdf = gpd.GeoDataFrame(polygons)\n",
    "    gdf.crs = meta['crs']\n",
    "    gdf.to_crs(dst_crs, inplace=True)\n",
    "    \n",
    "    save_path = save_path + \".temp\" \n",
    "    gdf.to_file(save_path, driver='GeoJSON')\n",
    "    os.rename(save_path, save_path[:-5])\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find tile indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = f\"/home/{os.getenv('NB_USER')}/work\"\n",
    "\n",
    "API_KEY = os.path.join(BASE, \".secret/sentinel2_google_api_key.json\")\n",
    "LOAD_DIR = os.path.join(BASE, \"satellite_imagery\")\n",
    "RESULTS_DIR = os.path.join(BASE, \"results/pbd\")\n",
    "\n",
    "PBD_DIR = os.path.join(BASE, \"notebooks/pbd\")\n",
    "\n",
    "BANDS = {'TCI', 'B08', }\n",
    "\n",
    "# CONSTRAINTS = {'NODATA_PIXEL_PERCENTAGE': 15.0, 'CLOUDY_PIXEL_PERCENTAGE': 40.0, }\n",
    "CONSTRAINTS = {'NODATA_PIXEL_PERCENTAGE': 10.0, 'CLOUDY_PIXEL_PERCENTAGE': 5.0, }\n",
    "\n",
    "DATE = \"2020-09-23\" #\"2019-06-04\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/work/notebooks/pbd/Pechenihy.geojson'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aoi_path = os.getenv(\"AOI\", os.path.join(BASE, \"notebooks/pbd/Pechenihy.geojson\")) \n",
    "# \"notebooks/pbd/plot_boundaries_20190604.geojson\"\n",
    "if not aoi_path:\n",
    "    raise RuntimeError(\"Add AOI env var for calculations\")\n",
    "    \n",
    "aoi_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentinel_tiles_path = \"sentinel2grid.geojson\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find overlap tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tileID</th>\n",
       "      <th>geometry</th>\n",
       "      <th>img_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36UYA</td>\n",
       "      <td>POLYGON Z ((36.78360 50.04479 0.00000, 36.7822...</td>\n",
       "      <td>2020-09-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tileID                                           geometry    img_date\n",
       "0  36UYA  POLYGON Z ((36.78360 50.04479 0.00000, 36.7822...  2020-09-23"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_tile_info = get_tiles(aoi_path, sentinel_tiles_path, DATE)\n",
    "date_tile_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(api_key, tiles, date, output_dir):\n",
    "    loader = Sentinel2Downloader(api_key)\n",
    "    loadings = dict()\n",
    "    for tile in tiles:\n",
    "        print(f\"Loading images for tile: {tile}...\")\n",
    "        loaded = loader.download('L2A',\n",
    "                                 [tile],\n",
    "                                 start_date=date,\n",
    "                                 end_date=date,\n",
    "                                 output_dir=output_dir,                       \n",
    "                                 bands=BANDS,\n",
    "                                constraints=CONSTRAINTS)\n",
    "        \n",
    "        print(f\"Loading images for tile {tile} finished\")\n",
    "        loadings[tile] = loaded\n",
    "    return loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images for tile: 36UYA...\n",
      "Loading images for tile 36UYA finished\n"
     ]
    }
   ],
   "source": [
    "loadings = load_images(API_KEY, date_tile_info.tileID.values, DATE, LOAD_DIR)\n",
    "\n",
    "if not loadings:\n",
    "    raise ValueError(\"Images not loaded. Change date or constraints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'36UYA': [('/home/jovyan/work/satellite_imagery/S2B_MSIL2A_20200923T083659_N0214_R064_T36UYA_20200925T161337/T36UYA_20200923T083659_TCI_10m.jp2',\n",
       "   'L2/tiles/36/U/YA/S2B_MSIL2A_20200923T083659_N0214_R064_T36UYA_20200925T161337.SAFE/GRANULE/L2A_T36UYA_A018537_20200923T083655/IMG_DATA/R10m/T36UYA_20200923T083659_TCI_10m.jp2'),\n",
       "  ('/home/jovyan/work/satellite_imagery/S2B_MSIL2A_20200923T083659_N0214_R064_T36UYA_20200925T161337/T36UYA_20200923T083659_B08_10m.jp2',\n",
       "   'L2/tiles/36/U/YA/S2B_MSIL2A_20200923T083659_N0214_R064_T36UYA_20200925T161337.SAFE/GRANULE/L2A_T36UYA_A018537_20200923T083655/IMG_DATA/R10m/T36UYA_20200923T083659_B08_10m.jp2'),\n",
       "  ('/home/jovyan/work/satellite_imagery/S2B_MSIL2A_20200923T083659_N0214_R064_T36UYA_20200925T161337/MTD_TL.xml',\n",
       "   'L2/tiles/36/U/YA/S2B_MSIL2A_20200923T083659_N0214_R064_T36UYA_20200925T161337.SAFE/GRANULE/L2A_T36UYA_A018537_20200923T083655/MTD_TL.xml')]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = [10., 13., 16., 19., 21.]\n",
    "min_edge_size = 200\n",
    "min_obj_size = 2000\n",
    "\n",
    "origin_name = os.path.basename(aoi_path).replace(\".geojson\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/satellite_imagery/S2B_MSIL2A_20200923T083659_N0214_R064_T36UYA_20200925T161337\n",
      "Processing 36UYA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [06:49<00:00, 409.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing 36UYA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>id</th>\n",
       "      <th>tileID</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POLYGON ((36.78341 50.04470, 36.78339 50.04452...</td>\n",
       "      <td>Pechenihy_0</td>\n",
       "      <td>36UYA</td>\n",
       "      <td>2020-09-23</td>\n",
       "      <td>2020-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POLYGON ((36.78444 50.04007, 36.78444 50.03998...</td>\n",
       "      <td>Pechenihy_1</td>\n",
       "      <td>36UYA</td>\n",
       "      <td>2020-09-23</td>\n",
       "      <td>2020-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POLYGON ((36.79111 50.03959, 36.79110 50.03950...</td>\n",
       "      <td>Pechenihy_2</td>\n",
       "      <td>36UYA</td>\n",
       "      <td>2020-09-23</td>\n",
       "      <td>2020-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POLYGON ((36.78399 50.03964, 36.78398 50.03955...</td>\n",
       "      <td>Pechenihy_3</td>\n",
       "      <td>36UYA</td>\n",
       "      <td>2020-09-23</td>\n",
       "      <td>2020-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POLYGON ((36.79429 50.03912, 36.79427 50.03894...</td>\n",
       "      <td>Pechenihy_4</td>\n",
       "      <td>36UYA</td>\n",
       "      <td>2020-09-23</td>\n",
       "      <td>2020-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2272</th>\n",
       "      <td>POLYGON ((36.68955 49.85554, 36.68954 49.85545...</td>\n",
       "      <td>Pechenihy_2272</td>\n",
       "      <td>36UYA</td>\n",
       "      <td>2020-09-23</td>\n",
       "      <td>2020-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>POLYGON ((36.70047 49.85456, 36.70046 49.85447...</td>\n",
       "      <td>Pechenihy_2273</td>\n",
       "      <td>36UYA</td>\n",
       "      <td>2020-09-23</td>\n",
       "      <td>2020-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2274</th>\n",
       "      <td>POLYGON ((36.68298 49.85512, 36.68297 49.85503...</td>\n",
       "      <td>Pechenihy_2274</td>\n",
       "      <td>36UYA</td>\n",
       "      <td>2020-09-23</td>\n",
       "      <td>2020-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2275</th>\n",
       "      <td>POLYGON ((36.78288 50.03977, 36.78287 50.03968...</td>\n",
       "      <td>Pechenihy_2275</td>\n",
       "      <td>36UYA</td>\n",
       "      <td>2020-09-23</td>\n",
       "      <td>2020-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2276</th>\n",
       "      <td>POLYGON ((36.68851 49.85287, 36.68851 49.85278...</td>\n",
       "      <td>Pechenihy_2276</td>\n",
       "      <td>36UYA</td>\n",
       "      <td>2020-09-23</td>\n",
       "      <td>2020-09-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2277 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               geometry              id  \\\n",
       "0     POLYGON ((36.78341 50.04470, 36.78339 50.04452...     Pechenihy_0   \n",
       "1     POLYGON ((36.78444 50.04007, 36.78444 50.03998...     Pechenihy_1   \n",
       "2     POLYGON ((36.79111 50.03959, 36.79110 50.03950...     Pechenihy_2   \n",
       "3     POLYGON ((36.78399 50.03964, 36.78398 50.03955...     Pechenihy_3   \n",
       "4     POLYGON ((36.79429 50.03912, 36.79427 50.03894...     Pechenihy_4   \n",
       "...                                                 ...             ...   \n",
       "2272  POLYGON ((36.68955 49.85554, 36.68954 49.85545...  Pechenihy_2272   \n",
       "2273  POLYGON ((36.70047 49.85456, 36.70046 49.85447...  Pechenihy_2273   \n",
       "2274  POLYGON ((36.68298 49.85512, 36.68297 49.85503...  Pechenihy_2274   \n",
       "2275  POLYGON ((36.78288 50.03977, 36.78287 50.03968...  Pechenihy_2275   \n",
       "2276  POLYGON ((36.68851 49.85287, 36.68851 49.85278...  Pechenihy_2276   \n",
       "\n",
       "     tileID  start_date    end_date  \n",
       "0     36UYA  2020-09-23  2020-09-23  \n",
       "1     36UYA  2020-09-23  2020-09-23  \n",
       "2     36UYA  2020-09-23  2020-09-23  \n",
       "3     36UYA  2020-09-23  2020-09-23  \n",
       "4     36UYA  2020-09-23  2020-09-23  \n",
       "...     ...         ...         ...  \n",
       "2272  36UYA  2020-09-23  2020-09-23  \n",
       "2273  36UYA  2020-09-23  2020-09-23  \n",
       "2274  36UYA  2020-09-23  2020-09-23  \n",
       "2275  36UYA  2020-09-23  2020-09-23  \n",
       "2276  36UYA  2020-09-23  2020-09-23  \n",
       "\n",
       "[2277 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame([])\n",
    "\n",
    "with tempfile.TemporaryDirectory(dir=PBD_DIR) as tmpdirname:   \n",
    "    for i, tile in tqdm(date_tile_info.iterrows(), total=date_tile_info.shape[0]):\n",
    "        try:\n",
    "            tile_folder = Path(loadings[tile.tileID][0][0]).parent\n",
    "            print(tile_folder)\n",
    "        except Exception as ex:\n",
    "            print(f\"Error for {tile.tileID}: {str(ex)}\")\n",
    "        else:\n",
    "            print(f\"Processing {tile.tileID}...\")\n",
    "    \n",
    "            raster_path = preprocess_sentinel_raw_data(\n",
    "                save_path=tmpdirname,\n",
    "                tile_folder=tile_folder,\n",
    "                aoi_mask=date_tile_info.loc[[i]]\n",
    "            )\n",
    "    \n",
    "            if len(th) == 1:\n",
    "                img, meta = find_segmentation_mask(\n",
    "                    raster_path, th[0],\n",
    "                    min_edge_size, min_obj_size\n",
    "                )\n",
    "            else:\n",
    "                img, meta = find_segmentation_mask_with_multiple_th(\n",
    "                    raster_path, th,\n",
    "                    min_edge_size, min_obj_size\n",
    "                )\n",
    "                df = pd.DataFrame({\"geometry\": polygonize(img, meta)})\n",
    "                df[\"id\"] = pd.Series(map(lambda x: f\"{origin_name}_{x}\", df.index.values))\n",
    "                df[\"tileID\"] = tile.tileID\n",
    "                df[\"start_date\"] = tile.img_date\n",
    "                df[\"end_date\"] = tile.img_date\n",
    "        \n",
    "\n",
    "            result_df = pd.concat([result_df, df])\n",
    "            \n",
    "            print(f\"Finished processing {tile.tileID}\")\n",
    "    # print(result_df)\n",
    "\n",
    "save_path = os.path.join(RESULTS_DIR, f\"{origin_name}_prediction.geojson\")\n",
    "save_polygons(result_df, meta['crs'], save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
