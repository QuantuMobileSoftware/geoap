{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting boundaries for given AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import rasterio.mask\n",
    "import tempfile\n",
    "\n",
    "from tqdm import tqdm\n",
    "from os.path import join, basename, split\n",
    "from skimage import measure\n",
    "from scipy.ndimage import rotate\n",
    "from rasterio.features import rasterize, shapes\n",
    "from shapely.geometry import Polygon, shape\n",
    "from pathlib import Path\n",
    "\n",
    "from sentinel2download.downloader import Sentinel2Downloader\n",
    "from preprocessing import preprocess_sentinel_raw_data, read_raster\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tiles(aoi_path, sentinel_tiles_path, date):\n",
    "    '''\n",
    "    Returns Sentinel-2 tiles that intersects with specified AoI.\n",
    "\n",
    "        Parameters:\n",
    "            aoi_path (str): Path to geojson/shp file with AoI to process.\n",
    "            sentinel_tiles_path (str): Path to geojson/shp file with all Sentinel-2 tiles.\n",
    "            date (str): Date in %Y%m%d format.\n",
    "\n",
    "        Returns:\n",
    "            date_tile_info (GeoDataFrame): Filtered tiles (tileID, geometry, date).\n",
    "    '''\n",
    "    aoi_file = gpd.read_file(aoi_path)\n",
    "    sentinel_tiles = gpd.read_file(sentinel_tiles_path)\n",
    "    sentinel_tiles.set_index(\"Name\", drop=False, inplace=True)\n",
    "\n",
    "    best_interseciton = {\"tileID\": [], \"geometry\": []}\n",
    "    rest_aoi = aoi_file.copy()\n",
    "\n",
    "    while rest_aoi.area.sum() > 0:\n",
    "        res_intersection = gpd.overlay(rest_aoi, sentinel_tiles, how=\"intersection\")\n",
    "        biggest_area_idx = res_intersection.area.argmax()\n",
    "\n",
    "        tileID = res_intersection.loc[biggest_area_idx, \"Name\"]\n",
    "        this_aoi = res_intersection.loc[biggest_area_idx, \"geometry\"]\n",
    "\n",
    "        best_interseciton[\"tileID\"].append(tileID)\n",
    "        best_interseciton[\"geometry\"].append(this_aoi)\n",
    "\n",
    "        biggest_intersection = sentinel_tiles.loc[[tileID]]\n",
    "        rest_aoi = gpd.overlay(rest_aoi, biggest_intersection, how=\"difference\")\n",
    "        sentinel_tiles = sentinel_tiles.loc[res_intersection[\"Name\"]]\n",
    "\n",
    "    date_tile_info = gpd.GeoDataFrame(best_interseciton)\n",
    "    date_tile_info[\"img_date\"] = date\n",
    "    date_tile_info.crs = aoi_file.crs\n",
    "    \n",
    "    return date_tile_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_segmentation_mask_with_multiple_th(image_path, thresholds, min_edge_size, min_obj_size, th_size=(11, 3)):\n",
    "    '''\n",
    "    Run segmentation on the given raster to find edges. \n",
    "    Combine multiple predictions with different thresholds with cv2.adaptiveThreshold.\n",
    "\n",
    "        Parameters:\n",
    "            image_path (str): Path to raster which will be processed.\n",
    "            thresholds (:obj:`list` of :obj:`float`): List of thresholds used to filter weak edges.\n",
    "            min_edge_size (int): Edges with lower size will be filtered.\n",
    "            min_obj_size (int): Instances with lower size will be filtered.\n",
    "            th_size (:obj:`tuple` of :obj:`int`): Size of cv2.adaptiveThreshold filter.\n",
    "\n",
    "        Returns:\n",
    "            img (numpy.array): Binary image with segmented instances.\n",
    "            meta (dict): Source raster metadata\n",
    "    '''\n",
    "    bands, meta = read_raster(image_path)\n",
    "    results = [None] * len(thresholds)\n",
    "    for i, th in enumerate(thresholds):\n",
    "        results[i], _ = find_segmentation_mask(image_path, th, min_edge_size, min_obj_size)\n",
    "    combined = np.mean(results, 0).astype(np.uint8)\n",
    "    thresholded = cv2.adaptiveThreshold(\n",
    "        combined,\n",
    "        255,\n",
    "        cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "        cv2.THRESH_BINARY,\n",
    "        *th_size\n",
    "    )\n",
    "    labeled = label_detected_instances(thresholded)\n",
    "    labeled = remove_background(labeled, bands)\n",
    "    labeled[thresholded == 0] = 0\n",
    "    img = convert_to_binary(labeled)\n",
    "\n",
    "    return img, meta\n",
    "\n",
    "\n",
    "def find_segmentation_mask(image_path, edge_combination_th, min_edge_size, min_obj_size):\n",
    "    '''\n",
    "    Run segmentation on the given raster to find edges.\n",
    "\n",
    "        Parameters:\n",
    "            image_path (str): Path to raster which will be processed.\n",
    "            edge_combination_th (float): Threshold that used to filter weak edges.\n",
    "            min_edge_size (int): Edges with lower size will be filtered.\n",
    "            min_obj_size (int): Instances with lower size will be filtered.\n",
    "\n",
    "        Returns:\n",
    "            binary_img (numpy.array): Binary image with segmented instances.\n",
    "            meta (dict): Source raster metadata\n",
    "    '''\n",
    "    bands, meta = read_raster(image_path)\n",
    "    avg_std = compute_image_standard_deviation(bands)\n",
    "    filter_list = create_edging_filters()\n",
    "    edges = apply_edging_filters(avg_std, filter_list)\n",
    "    edge_direction_list = combine_edges_layers(avg_std, edges, edge_combination_th)\n",
    "    edge_direction_list = remove_short_edges(edge_direction_list, min_edge_size)\n",
    "    binary_mask = edges_union(edge_direction_list)\n",
    "    labeled_image = label_detected_instances(binary_mask)\n",
    "    labeled_image = remove_small_objects(labeled_image, min_obj_size)\n",
    "    labeled_image = remove_background(labeled_image, bands)\n",
    "    binary_img = convert_to_binary(labeled_image)\n",
    "\n",
    "    return binary_img, meta\n",
    "\n",
    "\n",
    "def compute_image_standard_deviation(bands, kernel_size=(5, 5)):\n",
    "    std_list = [\n",
    "        find_edges_with_standard_deviation(b, kernel_size) for b in bands\n",
    "    ]\n",
    "    return np.mean(std_list, 0)\n",
    "\n",
    "\n",
    "def find_edges_with_standard_deviation(sample, filter_size=(3, 3)):\n",
    "    mean = cv2.blur(sample, filter_size)\n",
    "    mean_sqr = cv2.blur(sample * sample, filter_size)\n",
    "    std = cv2.sqrt(mean_sqr - mean*mean)\n",
    "    return std\n",
    "\n",
    "\n",
    "def create_edging_filters(length=13, count=16):\n",
    "    base_filter = np.array([\n",
    "        [-1] * length,\n",
    "        [1] * length,\n",
    "        [0] * length,\n",
    "    ])\n",
    "    filter_list = [None] * count * 2\n",
    "    filter_list[0] = base_filter\n",
    "    step = 180 / count\n",
    "\n",
    "    for i in range(count // 2):\n",
    "        filter_ = rotate(base_filter, i * step, order=0)\n",
    "        filter_list[i*4] = filter_\n",
    "        for j in range(1, 4):\n",
    "            filter_list[i*4+j] = np.rot90(filter_, j)\n",
    "\n",
    "    return filter_list\n",
    "\n",
    "\n",
    "def apply_edging_filters(sample, filter_list):\n",
    "    return [cv2.filter2D(sample, -1, f) for f in filter_list]\n",
    "\n",
    "\n",
    "def combine_edges_layers(avg_std, edges, th):\n",
    "    filter_count = len(edges) // 2\n",
    "    local_max_left = [None] * filter_count\n",
    "    local_max_right = [None] * filter_count\n",
    "\n",
    "    for i in range(filter_count // 2):\n",
    "        local_max_left[2*i] = cv2.bitwise_and(avg_std, edges[4*i])\n",
    "        local_max_left[2*i+1] = cv2.bitwise_and(avg_std, edges[4*i+1])\n",
    "        local_max_right[2*i] = cv2.bitwise_and(avg_std, edges[4*i+2])\n",
    "        local_max_right[2*i+1] = cv2.bitwise_and(avg_std, edges[4*i+3])\n",
    "\n",
    "    local_max_left = np.asanyarray(local_max_left)\n",
    "    local_max_right = np.asanyarray(local_max_right)\n",
    "\n",
    "    combined_result = np.zeros_like(local_max_left, np.uint8)\n",
    "    combined_result[\n",
    "        (local_max_left > 0) &\n",
    "        (local_max_right > 0) &\n",
    "        (local_max_left + local_max_right > th)\n",
    "    ] = 1\n",
    "\n",
    "    return combined_result\n",
    "\n",
    "\n",
    "def remove_short_edges(edge_direction_list, min_edge_size):\n",
    "    res = [None] * len(edge_direction_list)\n",
    "    for i, edge_direction in enumerate(edge_direction_list):\n",
    "        labeled_image = label_detected_instances(edge_direction, 0, 2)\n",
    "        labels, counts_labels = np.unique(labeled_image, return_counts=True)\n",
    "        edge_direction = np.isin(\n",
    "            labeled_image,\n",
    "            labels[counts_labels > min_edge_size]\n",
    "        ) & (edge_direction > 0)\n",
    "\n",
    "        res[i] = edge_direction.astype(np.uint8)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def edges_union(edges):\n",
    "    result = edges[0]\n",
    "    for e in edges[1:]:\n",
    "        result = cv2.bitwise_or(result, e)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def label_detected_instances(binary_mask, background=1, connectivity=2):\n",
    "    return measure.label(\n",
    "        binary_mask,\n",
    "        background=background,\n",
    "        connectivity=connectivity\n",
    "    )\n",
    "\n",
    "\n",
    "def remove_small_objects(labeled_image, min_obj_size):\n",
    "    labels, counts_labels = np.unique(labeled_image, return_counts=True)\n",
    "    labeled_image[np.isin(\n",
    "        labeled_image,\n",
    "        labels[counts_labels < min_obj_size]\n",
    "    )] = 0\n",
    "    return labeled_image\n",
    "\n",
    "\n",
    "def remove_background(prediction, bands):\n",
    "    mask = np.sum(bands, axis=0) == 0\n",
    "    prediction[mask] = 0\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def convert_to_binary(img):\n",
    "    img[img > 0] = 255\n",
    "    return img.astype(np.uint8)\n",
    "\n",
    "\n",
    "def polygonize(binary_img, meta, transform=True):\n",
    "    polygons = shapes(\n",
    "        binary_img, \n",
    "        binary_img, \n",
    "        transform=meta[\"transform\"],\n",
    "        connectivity=8\n",
    "    )\n",
    "    return [shape(poly) for poly, _ in polygons]\n",
    "\n",
    "\n",
    "def process_polygons(result_df, current_crs, limit=500, dst_crs=\"EPSG:4326\"):\n",
    "    \"\"\"\n",
    "    Prepare result Dataframe with polygons\n",
    "\n",
    "        Parameters:\n",
    "            result_df (pd.DataFrame): Result DataFrame\n",
    "            limit (int): min area for polygon in m2\n",
    "        Returns:\n",
    "            GeoDataFrame: GeoDataFrame ready for saving\n",
    "    \"\"\"\n",
    "        \n",
    "    gdf = gpd.GeoDataFrame(result_df)\n",
    "    gdf.crs = current_crs\n",
    "    \n",
    "    # fix invalid polygons\n",
    "    gdf[\"geometry\"] = gdf.apply(lambda row: row.geometry.buffer(0), axis=1)\n",
    "    # select only valid polygons\n",
    "    gdf = gdf.loc[gdf.is_valid]\n",
    "\n",
    "    # print(gdf.crs)\n",
    "    gdf = gdf.loc[gdf.area >= limit]\n",
    "    \n",
    "    gdf.to_crs(dst_crs, inplace=True)\n",
    "    \n",
    "    return gdf\n",
    "\n",
    "\n",
    "def save_polygons(gdf, save_path):\n",
    "    if len(gdf) == 0:\n",
    "        print('No polygons detected.')\n",
    "        return\n",
    "\n",
    "    directory = os.path.dirname(save_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "    save_path = save_path + \".temp\" \n",
    "    gdf.to_file(save_path, driver='GeoJSON')\n",
    "    os.rename(save_path, save_path[:-5])\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find tile indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = f\"/home/{os.getenv('NB_USER')}/work\"\n",
    "\n",
    "API_KEY = os.path.join(BASE, \".secret/sentinel2_google_api_key.json\")\n",
    "LOAD_DIR = os.path.join(BASE, \"satellite_imagery\")\n",
    "RESULTS_DIR = os.path.join(BASE, \"results/pbd\")\n",
    "\n",
    "PBD_DIR = os.path.join(BASE, \"notebooks/pbd\")\n",
    "\n",
    "BANDS = {'TCI', 'B08', }\n",
    "\n",
    "CONSTRAINTS = {'NODATA_PIXEL_PERCENTAGE': 15.0, 'CLOUDY_PIXEL_PERCENTAGE': 40.0, }\n",
    "# CONSTRAINTS = {'NODATA_PIXEL_PERCENTAGE': 10.0, 'CLOUDY_PIXEL_PERCENTAGE': 5.0, }\n",
    "\n",
    "DATE = \"2019-06-04\" # \"2020-09-23\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/work/notebooks/pbd/plot_boundaries_20190604.geojson'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aoi_path = os.getenv(\"AOI\", os.path.join(BASE, \"notebooks/pbd/plot_boundaries_20190604.geojson\")) # \"notebooks/pbd/Pechenihy.geojson\"\n",
    "# \"notebooks/pbd/plot_boundaries_20190604.geojson\"\n",
    "if not aoi_path:\n",
    "    raise RuntimeError(\"Add AOI env var for calculations\")\n",
    "    \n",
    "aoi_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentinel_tiles_path = \"sentinel2grid.geojson\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find overlap tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tileID</th>\n",
       "      <th>geometry</th>\n",
       "      <th>img_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17SLD</td>\n",
       "      <td>POLYGON Z ((-83.05615 39.18668 0.00000, -83.31...</td>\n",
       "      <td>2019-06-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17SKD</td>\n",
       "      <td>POLYGON Z ((-83.31631 39.20046 0.00000, -83.39...</td>\n",
       "      <td>2019-06-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tileID                                           geometry    img_date\n",
       "0  17SLD  POLYGON Z ((-83.05615 39.18668 0.00000, -83.31...  2019-06-04\n",
       "1  17SKD  POLYGON Z ((-83.31631 39.20046 0.00000, -83.39...  2019-06-04"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_tile_info = get_tiles(aoi_path, sentinel_tiles_path, DATE)\n",
    "date_tile_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(api_key, tiles, date, output_dir):\n",
    "    loader = Sentinel2Downloader(api_key)\n",
    "    loadings = dict()\n",
    "    for tile in tiles:\n",
    "        print(f\"Loading images for tile: {tile}...\")\n",
    "        loaded = loader.download('L2A',\n",
    "                                 [tile],\n",
    "                                 start_date=date,\n",
    "                                 end_date=date,\n",
    "                                 output_dir=output_dir,                       \n",
    "                                 bands=BANDS,\n",
    "                                constraints=CONSTRAINTS)\n",
    "        \n",
    "        print(f\"Loading images for tile {tile} finished\")\n",
    "        loadings[tile] = loaded\n",
    "    return loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images for tile: 17SLD...\n",
      "Loading images for tile 17SLD finished\n",
      "Loading images for tile: 17SKD...\n",
      "Loading images for tile 17SKD finished\n"
     ]
    }
   ],
   "source": [
    "loadings = load_images(API_KEY, date_tile_info.tileID.values, DATE, LOAD_DIR)\n",
    "\n",
    "if not loadings:\n",
    "    raise ValueError(\"Images not loaded. Change date or constraints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'17SLD': [('/home/jovyan/work/satellite_imagery/S2A_MSIL2A_20190604T161901_N0212_R040_T17SLD_20190604T204200/T17SLD_20190604T161901_TCI_10m.jp2',\n",
       "   'L2/tiles/17/S/LD/S2A_MSIL2A_20190604T161901_N0212_R040_T17SLD_20190604T204200.SAFE/GRANULE/L2A_T17SLD_A020629_20190604T162855/IMG_DATA/R10m/T17SLD_20190604T161901_TCI_10m.jp2'),\n",
       "  ('/home/jovyan/work/satellite_imagery/S2A_MSIL2A_20190604T161901_N0212_R040_T17SLD_20190604T204200/MTD_TL.xml',\n",
       "   'L2/tiles/17/S/LD/S2A_MSIL2A_20190604T161901_N0212_R040_T17SLD_20190604T204200.SAFE/GRANULE/L2A_T17SLD_A020629_20190604T162855/MTD_TL.xml'),\n",
       "  ('/home/jovyan/work/satellite_imagery/S2A_MSIL2A_20190604T161901_N0212_R040_T17SLD_20190604T204200/T17SLD_20190604T161901_B08_10m.jp2',\n",
       "   'L2/tiles/17/S/LD/S2A_MSIL2A_20190604T161901_N0212_R040_T17SLD_20190604T204200.SAFE/GRANULE/L2A_T17SLD_A020629_20190604T162855/IMG_DATA/R10m/T17SLD_20190604T161901_B08_10m.jp2')],\n",
       " '17SKD': [('/home/jovyan/work/satellite_imagery/S2A_MSIL2A_20190604T161901_N0212_R040_T17SKD_20190604T204200/T17SKD_20190604T161901_B08_10m.jp2',\n",
       "   'L2/tiles/17/S/KD/S2A_MSIL2A_20190604T161901_N0212_R040_T17SKD_20190604T204200.SAFE/GRANULE/L2A_T17SKD_A020629_20190604T162855/IMG_DATA/R10m/T17SKD_20190604T161901_B08_10m.jp2'),\n",
       "  ('/home/jovyan/work/satellite_imagery/S2A_MSIL2A_20190604T161901_N0212_R040_T17SKD_20190604T204200/T17SKD_20190604T161901_TCI_10m.jp2',\n",
       "   'L2/tiles/17/S/KD/S2A_MSIL2A_20190604T161901_N0212_R040_T17SKD_20190604T204200.SAFE/GRANULE/L2A_T17SKD_A020629_20190604T162855/IMG_DATA/R10m/T17SKD_20190604T161901_TCI_10m.jp2'),\n",
       "  ('/home/jovyan/work/satellite_imagery/S2A_MSIL2A_20190604T161901_N0212_R040_T17SKD_20190604T204200/MTD_TL.xml',\n",
       "   'L2/tiles/17/S/KD/S2A_MSIL2A_20190604T161901_N0212_R040_T17SKD_20190604T204200.SAFE/GRANULE/L2A_T17SKD_A020629_20190604T162855/MTD_TL.xml')]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = [10., 13., 16., 19., 21.]\n",
    "min_edge_size = 200\n",
    "min_obj_size = 2000\n",
    "\n",
    "origin_name = os.path.basename(aoi_path).replace(\".geojson\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/satellite_imagery/S2A_MSIL2A_20190604T161901_N0212_R040_T17SLD_20190604T204200\n",
      "Processing 17SLD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [03:45<03:45, 225.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing 17SLD\n",
      "/home/jovyan/work/satellite_imagery/S2A_MSIL2A_20190604T161901_N0212_R040_T17SKD_20190604T204200\n",
      "Processing 17SKD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [05:23<00:00, 161.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing 17SKD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>id</th>\n",
       "      <th>tileID</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MULTIPOLYGON (((-83.07219 39.38320, -83.07219 ...</td>\n",
       "      <td>plot_boundaries_20190604_1</td>\n",
       "      <td>17SLD</td>\n",
       "      <td>2019-06-04</td>\n",
       "      <td>2019-06-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POLYGON ((-83.08934 39.38217, -83.08864 39.382...</td>\n",
       "      <td>plot_boundaries_20190604_2</td>\n",
       "      <td>17SLD</td>\n",
       "      <td>2019-06-04</td>\n",
       "      <td>2019-06-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>POLYGON ((-83.10794 39.37931, -83.10748 39.379...</td>\n",
       "      <td>plot_boundaries_20190604_8</td>\n",
       "      <td>17SLD</td>\n",
       "      <td>2019-06-04</td>\n",
       "      <td>2019-06-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MULTIPOLYGON (((-83.10632 39.37925, -83.10632 ...</td>\n",
       "      <td>plot_boundaries_20190604_14</td>\n",
       "      <td>17SLD</td>\n",
       "      <td>2019-06-04</td>\n",
       "      <td>2019-06-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>POLYGON ((-83.06693 39.37816, -83.06681 39.378...</td>\n",
       "      <td>plot_boundaries_20190604_19</td>\n",
       "      <td>17SLD</td>\n",
       "      <td>2019-06-04</td>\n",
       "      <td>2019-06-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>POLYGON ((-83.35024 39.21007, -83.35013 39.210...</td>\n",
       "      <td>plot_boundaries_20190604_1481</td>\n",
       "      <td>17SKD</td>\n",
       "      <td>2019-06-04</td>\n",
       "      <td>2019-06-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>POLYGON ((-83.31670 39.20443, -83.31647 39.204...</td>\n",
       "      <td>plot_boundaries_20190604_1482</td>\n",
       "      <td>17SKD</td>\n",
       "      <td>2019-06-04</td>\n",
       "      <td>2019-06-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>POLYGON ((-83.34039 39.20270, -83.34004 39.202...</td>\n",
       "      <td>plot_boundaries_20190604_1484</td>\n",
       "      <td>17SKD</td>\n",
       "      <td>2019-06-04</td>\n",
       "      <td>2019-06-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>POLYGON ((-83.32383 39.20267, -83.32278 39.202...</td>\n",
       "      <td>plot_boundaries_20190604_1486</td>\n",
       "      <td>17SKD</td>\n",
       "      <td>2019-06-04</td>\n",
       "      <td>2019-06-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>MULTIPOLYGON (((-83.31932 39.22762, -83.31932 ...</td>\n",
       "      <td>plot_boundaries_20190604_1487</td>\n",
       "      <td>17SKD</td>\n",
       "      <td>2019-06-04</td>\n",
       "      <td>2019-06-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1795 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               geometry  \\\n",
       "1     MULTIPOLYGON (((-83.07219 39.38320, -83.07219 ...   \n",
       "2     POLYGON ((-83.08934 39.38217, -83.08864 39.382...   \n",
       "8     POLYGON ((-83.10794 39.37931, -83.10748 39.379...   \n",
       "14    MULTIPOLYGON (((-83.10632 39.37925, -83.10632 ...   \n",
       "19    POLYGON ((-83.06693 39.37816, -83.06681 39.378...   \n",
       "...                                                 ...   \n",
       "1481  POLYGON ((-83.35024 39.21007, -83.35013 39.210...   \n",
       "1482  POLYGON ((-83.31670 39.20443, -83.31647 39.204...   \n",
       "1484  POLYGON ((-83.34039 39.20270, -83.34004 39.202...   \n",
       "1486  POLYGON ((-83.32383 39.20267, -83.32278 39.202...   \n",
       "1487  MULTIPOLYGON (((-83.31932 39.22762, -83.31932 ...   \n",
       "\n",
       "                                 id tileID  start_date    end_date  \n",
       "1        plot_boundaries_20190604_1  17SLD  2019-06-04  2019-06-04  \n",
       "2        plot_boundaries_20190604_2  17SLD  2019-06-04  2019-06-04  \n",
       "8        plot_boundaries_20190604_8  17SLD  2019-06-04  2019-06-04  \n",
       "14      plot_boundaries_20190604_14  17SLD  2019-06-04  2019-06-04  \n",
       "19      plot_boundaries_20190604_19  17SLD  2019-06-04  2019-06-04  \n",
       "...                             ...    ...         ...         ...  \n",
       "1481  plot_boundaries_20190604_1481  17SKD  2019-06-04  2019-06-04  \n",
       "1482  plot_boundaries_20190604_1482  17SKD  2019-06-04  2019-06-04  \n",
       "1484  plot_boundaries_20190604_1484  17SKD  2019-06-04  2019-06-04  \n",
       "1486  plot_boundaries_20190604_1486  17SKD  2019-06-04  2019-06-04  \n",
       "1487  plot_boundaries_20190604_1487  17SKD  2019-06-04  2019-06-04  \n",
       "\n",
       "[1795 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame([])\n",
    "\n",
    "with tempfile.TemporaryDirectory(dir=PBD_DIR) as tmpdirname:   \n",
    "    for i, tile in tqdm(date_tile_info.iterrows(), total=date_tile_info.shape[0]):\n",
    "        try:\n",
    "            tile_folder = Path(loadings[tile.tileID][0][0]).parent\n",
    "            print(tile_folder)\n",
    "        except Exception as ex:\n",
    "            print(f\"Error for {tile.tileID}: {str(ex)}\")\n",
    "        else:\n",
    "            print(f\"Processing {tile.tileID}...\")\n",
    "    \n",
    "            raster_path = preprocess_sentinel_raw_data(\n",
    "                save_path=tmpdirname,\n",
    "                tile_folder=tile_folder,\n",
    "                aoi_mask=date_tile_info.loc[[i]]\n",
    "            )\n",
    "    \n",
    "            if len(th) == 1:\n",
    "                img, meta = find_segmentation_mask(\n",
    "                    raster_path, th[0],\n",
    "                    min_edge_size, min_obj_size\n",
    "                )\n",
    "            else:\n",
    "                img, meta = find_segmentation_mask_with_multiple_th(\n",
    "                    raster_path, th,\n",
    "                    min_edge_size, min_obj_size\n",
    "                )\n",
    "                df = pd.DataFrame({\"geometry\": polygonize(img, meta)})\n",
    "                df[\"id\"] = pd.Series(map(lambda x: f\"{origin_name}_{x}\", df.index.values))\n",
    "                df[\"tileID\"] = tile.tileID\n",
    "                df[\"start_date\"] = tile.img_date\n",
    "                df[\"end_date\"] = tile.img_date\n",
    "        \n",
    "\n",
    "            result_df = pd.concat([result_df, df])\n",
    "            \n",
    "            print(f\"Finished processing {tile.tileID}\")\n",
    "    # print(result_df)\n",
    "\n",
    "\n",
    "gdf = process_polygons(result_df, meta['crs'])\n",
    "save_path = os.path.join(RESULTS_DIR, f\"{origin_name}_prediction_vy_valid.geojson\")\n",
    "save_polygons(gdf, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
